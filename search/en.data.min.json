[{"id":0,"href":"/pix/adr/0001-enregistrer-les-decisions-concernant-l-architecture/","title":"0001 Enregistrer Les Decisions Concernant L Architecture","parent":"Adr","content":" 1. Enregistrer les décisions concernant l\u0026rsquo;architecture Date : 2019-04-25\nÉtat Accepté\nContexte Sur ce projet, nous avons besoin de :\nprendre facilement des décisions concernant l\u0026rsquo;architecture; pouvoir comprendre pourquoi une décision a été prise dans le passé, afin de prendre une autre décision si les circonstances ont changé; savoir qu\u0026rsquo;une décision donnée a été modifiée ou remplacée par une décision ultérieure. Voir Voir l\u0026rsquo;issue originale\nSolution n°1 : Architecture Decision Record Description\nLes Architecture Decision Records (ADR) de Michael Nygard obéissent aux règles suivantes (article original):\nwe will keep a collection of records for \u0026ldquo;architecturally significant\u0026rdquo; decisions this collection will be kept in the project repository each record will be a short text file, with just a few parts if a decision is reversed, we will keep the old one around, marking it as superseded we will use a lightweight text formatting language Avantage(s):\nouvrir une pull request sur une ADR permettent un échange pour prendre une décision d\u0026rsquo;architecture accessibles au quotidien sans coût d\u0026rsquo;outillage la connaissance reste dans le projet, malgré le départ des développeurs cela permet de partager la connaissance au reste du monde, le repository étant Open-source Inconvénient(s):\nil faut passer du temps à rédiger les ADR Solution n°2 : Connaissance tacite et informelle Description\nSi les développeurs :\ntravaillent en pair-programming ou en mob programming; effectuent des revues de code; changent d\u0026rsquo;équipe régulièrement. Alors il est possible que :\nles développeurs se réunissent pour prendre des décisions d\u0026rsquo;architecture; les développeurs ayant pris ces décisions d\u0026rsquo;architecture les exposent par oral à ceux récemment arrivés; cette exposition se fait lors du développement et des revues de code. Avantage(s):\naucun coût direct de mise en oeuvre Inconvénient(s):\nsi la transmission n\u0026rsquo;est pas effectuée, la connaissance est perdue la connaissance n\u0026rsquo;est pas partagée avec le reste du monde Décision Nous avons choisi la solution n°1, à savoir les ADR, car le temps passé à créer un ADR est minimal par rapport au risque encouru si la connaissance est perdue.\nConséquences Matérialiser cette décision sous la forme d\u0026rsquo;un ADR autoportant.\nEn d\u0026rsquo;autres termes, ce fichier est :\nle premier ADR; un template pour les prochains ADR. Il existe également un outil CLI (adr-tools) qui permet de générer ce template.\n"},{"id":1,"href":"/pix/adr/0002-style-d-architecture/","title":"0002 Style D Architecture","parent":"Adr","content":" 2. Style d\u0026rsquo;architecture Date : 2019-08-22\nÉtat Accepté\nContexte La mission de Pix est d\u0026rsquo;accompagner la société et les citoyens à prendre le train du numérique dans les meilleures conditions et délais.\nPour accomplir cet objectif ambitieux, Pix table sur une stratégie à 3 dimensions :\nfournir un (bouquet de) service(s) de qualité accessible au plus grand nombre co-construire un standard reconnu et validé par tous (établissements et structures scolaires ou d\u0026rsquo;enseignement supérieur, organisations profesionnelles / publiques / privées, administrations, associations, etc.) développer une communauté et une culture Pix Une partie du premier axe d\u0026rsquo;action est adressée à travers le développement d\u0026rsquo;une \u0026ldquo;plateforme numérique en ligne\u0026rdquo;.\nÉtant donné l\u0026rsquo;aspect très grand public du projet, la plateforme doit répondre aux exigences de qualité suivantes :\ninnovante, moderne, fiable, accessible, sécurisée, performante Par ailleurs, la plateforme doit respecter les caractéristiques suivantes :\nréactive par rapport au marché de l\u0026rsquo;évaluation et de la certification des compétences numériques en ligne, et à une approche \u0026ldquo;Lean Product Management\u0026rdquo; évolutive selon la couverture de marché et la complexité grandissante du métier ouverte (i.e. interopérable) des SI tiers ou externes, en lecture/écriture, avec des flux entrant/sortant Enfin, la plateforme doit permettre simplement, rapidement et à moindre coût l\u0026rsquo;émergence, l\u0026rsquo;ajout, la suppression, la mise à jour et la maintenance de services SI de différente sorte, en fonction des besoins métier ou technique.\nDécision L\u0026rsquo;un des éléments essentiels dans la mise en place d\u0026rsquo;une plateforme, est le développement possible et effectif d\u0026rsquo;un \u0026ldquo;écosystème\u0026rdquo;.\nDans ce contexte, on appelle écosystème l\u0026rsquo;ensemble formé entre des composants SI, leurs interactions les uns avec les autres et l\u0026rsquo;environnement dans lequel ils sont exécutés. Exemples de composants : une webapp Ember, une webapp Rails, une API, une base de données, un server SMTP, un service SaaS, etc.\nLe style d\u0026rsquo;architecture retenue pour la mise en œuvre de la plateforme Pix et de son écosystème est le suivant :\n1 API métier (back) sécurisée, fiable et performante gérant l\u0026rsquo;accès et la manipulation de différents référentiels de données afin d\u0026rsquo;alimenter plusieurs applications clients (front) dédiées et optimisées pour un usage et une audience particuliers Tout accès ou manipulation d\u0026rsquo;un référentiel de données (base de données, service en ligne, cache applicatif, etc.) DOIT être effectué et restreint à l\u0026rsquo;API.\nUne application front NE DOIT PAS accéder directement un référentiel de données, afin de diminuer le risque lié à la sécurisation des données personnelles ou business.\nUne application front DOIT couvrir un seul périmètre métier, afin d\u0026rsquo;offrir aux utilisateurs du service concerné une expérience optimale, limiter la complexité lors des développements et favoriser des mises à disposition du public / marché fréquentes et rapides.\nL\u0026rsquo;intelligence métier DOIT être codée ou située dans l\u0026rsquo;API. Elle NE DOIT PAS être dans les applications front.\nToute application front DOIT permettre aux utilisateurs un usage confortable et adapté à leurs besoins. Pour ce faire, une application front PEUT proposer des contrôles de surface et autres interactions mouf-mouf. Une application front PEUT \u0026ldquo;imiter\u0026rdquo; afin de les prévenir certains contrôles métier, qui DOIVENT néanmoins être présents côté back.\nConséquences Ce style d\u0026rsquo;architecture nécessite de gérer plusieurs projets / applications.\nPar ailleurs, afin de proposer une expérience utilisateur optimale, certaines règles métier peuvent être codées plusieurs fois (dans l\u0026rsquo;API et dans le·s front·s correspondant·s).\nEnfin, certaines fonctionnalités techniques basiques peuvent être dupliquées entre plusieurs applications front.\n"},{"id":2,"href":"/pix/adr/0003-langages-frameworks-et-technologies/","title":"0003 Langages Frameworks Et Technologies","parent":"Adr","content":" 3. Langages, frameworks et technologies Date: 2019-08-23\nÉtat Accepted\nContexte Chez Pix, nous croyons que l\u0026rsquo;avenir de l\u0026rsquo;IT passe par :\nle Web plutôt que les clients lourds ou applications mobiles natives, l\u0026rsquo;Open Source plutôt que les solutions propriétaires et les standards universels (HTML, CSS, HTTP, REST, etc.) plutôt que des solutions inédites Sur la base de ces convictions et selon l\u0026rsquo;approche de design émergent, nous devons régulièrement faire face à des choix d\u0026rsquo;architecture, de services ou de technologies. Cette prise de décisions doit se faire en veillant à la cohérence, l\u0026rsquo;évolutivité et l\u0026rsquo;adéquation de la plateforme logicielle par raport à la mission de Pix et sa stratégie de développement dans le marché qui est le nôtre.\nDécision Limiter les technologies et leur diversité En phase avec le proverbe less is more, nous pensons que la simplicité d\u0026rsquo;un SI découle (entre autres) de la réduction des ressources impliquées et de leur bon usage, aux justes fins.\nPar ailleurs, limiter les technologies permet de limiter les expertises requises pour développer de façon autonome, productive et confortable le projet ; et ainsi :\nfaciliter le recrutement simplifier la montée en compétence des nouveaux membres de l\u0026rsquo;équipe réduire l\u0026rsquo;effort et le coût de maintenance Privilégier JavaScript Nous pensons que JavaScript est un langage d\u0026rsquo;avenir permettant dès aujourd\u0026rsquo;hui de développer tout type d\u0026rsquo;applications logicielles (IHM Web, API \u0026amp; back-office, CLI, scripts \u0026amp; utilitaires) avec un haut degré de qualité (en termes de complexité métier, UX, tech, archi ou méthodo).\nAinsi, nous adoptons JavaScript (langage), Node.js (plateforme) et NPM (écosystème) comme technologies centrales et principales de Pix.\nLa création d\u0026rsquo;applications Web, API, CLI ou de scripts DOIT privilégier une solution JS/Node.js. Pour rappel, JavaScript fait partie, avec HTML et CSS, des 3 langages supportés par tout navigateur Web récents ou moins.\nSi le service, l\u0026rsquo;activité ou le programme à accomplir ne s\u0026rsquo;y prête pas, on PEUT utiliser un autre langage, écosystème, technologies. Ex : pour faire du calcul de type Data Science, il semble préférable de privilégier Python ou R.\nNous faisons le choix de NPM comme gestionnaire de package plutôt que Yarn pour les raisons suivantes :\nNPM est nativement inclus dans Node.js, ce qui en fait le standard de facto NPM a rejoint Yarn niveaux fonctionnalités, performances et sécurité NPM conserve une longueur d\u0026rsquo;avance en termes de tendances Privilégier des solutions Open Source Nous privilégions l\u0026rsquo;usage de technologies Open Source pour les raisons suivantes :\nconvictions éthiques indépendance de Pix vis-à-vis d\u0026rsquo;éventuels éditeurs accès au code source qui permet de comprendre, étendre ou intégrer la solution à notre contexte / besoin accès à la communauté (plutôt qu\u0026rsquo;un obscur support) approche et solution plus proches des standards qualité de la solution (nombre de contributeurs potentiellement infini VS. une poignée d\u0026rsquo;employés) : bugs, sécurité, etc. coût / économie On PEUT toutefois utiliser des technologies ou services propriétaires si c\u0026rsquo;est la meilleure solution pour un problème donné, ex :\nMailjet pour la gestion d\u0026rsquo;e-mails, Airtable pour le référentiel pédagogique, prismic.io pour le contenu éditorial, Freshdesk pour le support. Conséquences L\u0026rsquo;ajout d\u0026rsquo;un langage, d\u0026rsquo;un framework ou de toute autre brique logicielle au sein du SI et de l\u0026rsquo;architecture de la plateforme Pix DOIT faire l\u0026rsquo;objet d\u0026rsquo;une étude approfondie. Le but de cette étude est de contrôler la complexité liée au nombre et à la nature des composants du SI ainsi qu\u0026rsquo;à leurs interactions ou interdépendances.\n"},{"id":3,"href":"/pix/adr/0004-traitement-type-date-sans-horaire-dans-pix/","title":"0004 Traitement Type Date Sans Horaire Dans Pix","parent":"Adr","content":" 4. Traitement du type date sans horaire dans Pix Date : 2019-11-04\nÉtat Accepted\nContexte Dans l\u0026rsquo;ensemble des données manipulées dans l\u0026rsquo;écosystème Pix se trouvent des données telles que des dates de création, de mise à jour, mais aussi des dates de naissance par exemple. Ces données, qui semblent juste représenter des dates, peuvent en réalité se diviser selon deux catégories :\nLes dates avec horaire qui consistent en de l\u0026rsquo;horodatage. Les dates sans horaire qui représentent simplement un jour précis. À ce jour, ces dates sont traitées sans distinction dans Pix. Le traitement, le formatage et le stockage ne sont pas uniformes dans l\u0026rsquo;ensemble du code produit et sont même parfois dictés par la dépendance à l\u0026rsquo;origine de la création de la valeur, et ce particulièrement pour la deuxième catégorie énoncée plus haut à savoir les dates sans horaire.\nDans les faits, cette catégorie de date se retrouve être traitée et stockée à la manière des dates avec horaire: un horaire sans fondement réel est assigné à ces dates, en général un horaire à minuit heure locale. L\u0026rsquo;effet de bord alors le plus critique est que la date soit modifiée lors de la transmission de la donnée entre deux machines n\u0026rsquo;ayant pas la même locale. Cet effet est visible sur nos machines locales :\n$ date Thu Nov 7 09:29:39 CET 2019 $ docker-compose exec -T postgres bash -c \u0026#39;date\u0026#39; Thu Nov 7 08:29:39 UTC 2019 Prenons en exemple la date du 23 Février 2018 (2018-02-23). Côté API, dans le cas initial où elle est représentée à l\u0026rsquo;aide de l\u0026rsquo;objet JS Date, nous obtenons en réalité 2018-02-23T00:00:00.000Z. Cette date est ensuite envoyée vers la base de données qui va la recevoir en tenant compte de sa propre locale, et va donc se transformer en 2018-02-22T23:00:00.000Z, puis tronquée pour correspondre à un type DATE de PostgreSQL pour finalement devenir \u0026lsquo;2018-02-22\u0026rsquo;. La date est donc définitivement altérée. Exemple de résultats dans les tests en local avant mise en application des recommandations :\n1) Integration | Repository | Session #get should return session informations in a session Object: AssertionError: expected { Object (id, accessCode, ...) } to have deep property \u0026#39;date\u0026#39; of Fri, 23 Feb 2018 00:00:00 GMT, but got Thu, 22 Feb 2018 23:00:00 GMT + expected - actual -[Date: 2018-02-22T23:00:00.000Z] +[Date: 2018-02-23T00:00:00.000Z] at Context.it.only (tests/integration/infrastructure/repositories/session-repository_test.js:193:37) Décision Il faut maîtriser le formatage des dates sans horaire à des points stratégiques des applications et être clair sur la manière de manipuler ce type de date.\nUne date sans horaire doit être représentée sous la forme d\u0026rsquo;une chaîne \u0026lsquo;YYYY-MM-DD\u0026rsquo; selon les directives de l\u0026rsquo;organisation internationale de normalisation (norme ISO 8601).\nDans l\u0026rsquo;écosystème Pix, nous nous assurons de cette représentation à 2 endroits stratégiques :\nÀ la conversion des valeurs brutes retournées par la base de données en type Javascript par l\u0026rsquo;interface node-postgres. À la sérialisation des valeurs générées par les applications fronts vers l\u0026rsquo;API. Conséquences Les valeurs lues depuis la base de données contenues dans une colonne ayant le type PostgreSQL DATE seront toujours retournées en chaîne \u0026lsquo;YYYY-MM-DD\u0026rsquo; :\nconst types = require(\u0026#39;pg\u0026#39;).types; types.setTypeParser(types.builtins.DATE, (value) =\u0026gt; value); Les dates sans horaire dans les applications fronts doivent être typées à l\u0026rsquo;aide de la transform créée à cet effet \u0026lsquo;date-only\u0026rsquo; :\n// certif/app/models/certification-candidate.js import DS from \u0026#39;ember-data\u0026#39;; export default DS.Model.extend({ firstName: DS.attr(\u0026#39;string\u0026#39;), lastName: DS.attr(\u0026#39;string\u0026#39;), birthdate: DS.attr(\u0026#39;date-only\u0026#39;), birthCity: DS.attr(\u0026#39;string\u0026#39;), birthProvinceCode: DS.attr(\u0026#39;string\u0026#39;), birthCountry: DS.attr(\u0026#39;string\u0026#39;), externalId: DS.attr(\u0026#39;string\u0026#39;), extraTimePercentage: DS.attr(\u0026#39;number\u0026#39;), }); // certif/app/transforms/date-only.js import DS from \u0026#39;ember-data\u0026#39;; export default DS.Transform.extend({ serialize: function(date) { return date; }, deserialize: function(date) { const dateRegex = \u0026#39;^[0-9]{4}-[0-9]{2}-[0-9]{2}$\u0026#39;; if (date.search(dateRegex) === 0) { return date; } return null; } }); Les dates sans horaire reçues dans l\u0026rsquo;API depuis l\u0026rsquo;extérieur doivent toujours être validées au moment de leur désérialisation :\n// api/infrastructure/serializers/certification-candidate-serializer.js deserialize(json) { if (!isValidDate(json.data.attributes.birthdate)) { throw new WrongDateFormatError(); } "},{"id":4,"href":"/pix/adr/0005-ajout-d-un-cache-memoire-distribute-pour-le-contenu-pedagogique/","title":"0005 Ajout D Un Cache Memoire Distribute Pour Le Contenu Pedagogique","parent":"Adr","content":" 5. Ajout d\u0026rsquo;un cache double-couches en-mémoire et distribué pour la gestion du contenu pédagogique Date : 2020-01-08\nÉtat Superseded\nContexte Le contenu pédagogique désigne l\u0026rsquo;ensemble des informations permettant d\u0026rsquo;évaluer les compétences numériques des utilisateurs : Domaines, Compétences, Tests, Épreuves, Sujets (Tubes), Acquis, Tutoriaux.\nCes informations sont définies et contenues dans un référentiel de données de type SaaS, Airtable. Cette solution impose une limite d\u0026rsquo;appel de 5 req/s. Au-delà de cette limite, toutes les requêtes à l\u0026rsquo;API d\u0026rsquo;Airtable sont bloquées pendant 30s.\nAfin de pallier à cette limite, un système de cache système a été mis en place, basé sur Redis. Le référentiel de données pédagogiques est rechargé quotidiennement, en récupérant toutes les données d\u0026rsquo;Airtables et en les stockant dans Redis. Ainsi, en utilisation normale, le système ne sollicite quasiment jamais Airtable.\nÀ date, le système de cache utilisé sur Pix n\u0026rsquo;est utilisé que pour le contenu pédagogique.\nUn cache basé sur Redis présente tout de même des défauts et limites :\nnombre de requêtes réseau nécessaires, notamment pour un appel de type GetNextChallenge nombre et durée de vie des connexions Redis (cf. issue Sentry) obligation de sérialisation/désérialisation des informations sous forme de String Par ailleurs, les données du référentiel sont stockées en double dans Redis :\nsous forme d\u0026rsquo;enregistrement individuel, ex : \u0026ldquo;Challenge_recAbcd\u0026rdquo;, \u0026ldquo;Challenge_recEfgh\u0026rdquo; sous forme de liste agrégée, ex : \u0026ldquo;Challenges\u0026rdquo; Le problème d\u0026rsquo;une telle gestion des données est qu\u0026rsquo;elle donne lieu à plusieurs scénarios permettant une désynchronisation des données agrégées ou individuelles.\nLe système actuel présente donc des limites bloquantes aussi bien techniques (perfs, charges) que fonctionnelles (qualité des données).\nDécision Afin d\u0026rsquo;améliorer les performances, tout en optimisant notre consommation de ressources, nous décidons de mettre en œuvre un cache applicatif multi-couches en-mémoire distribué.\nPar ailleurs, nous décidons de ne conserver que la forme agrégée des données stockées dans Redis, afin de consolider notre gestion des données référentielles.\nLa synchronisation des caches mémoires des différentes instances d\u0026rsquo;API se fait via le mécanisme de notifications (pub/sub) de Redis.\nConséquences Architecture D\u0026rsquo;un point de vue architecture logicielle, elle évolue comme tel :\nAvant :\nAprès :\nOptimisation des ressources \u0026amp; performances Les performances de l\u0026rsquo;API sont largement améliorées :\ndiminution du nombre des requêtes réseau, car (quasiment) plus besoin d\u0026rsquo;accéder à Redis diminution, de fait, du risque d\u0026rsquo;avoir des problèmes de connexion Redis diminution du nombre de traitements (sérialisation/deserialisation JS/string) lors des appels Redis diminution très importante, des temps de réponse moyenne augmentation proportionnelle, de la capacité à encaisser de la charge amélioration de la consistance + cohérence + fraîcheur des données pédagogiques Enrichissement de l\u0026rsquo;outillage de caching Plusieurs classes et types de cache (en mémoire, distribué, Redis) sont disponibles pour implémenter des caches avec des stratégies et dans des conditions spécifiques :\ncache mémoire cache distribué (basé sur Redis Pub/Sub) cache multi-niveau cache Redis Chaque brique de cache est conçue pour être générique et composable l\u0026rsquo;une avec/pour l\u0026rsquo;autre.\nLiens Introduction à la mise en cache par AWS (fr) Introduction à la mise en cache distribuée Avantages d\u0026rsquo;une mise en cache distribué (fr) Caches multi-niveaux (Wikipedia, en) "},{"id":5,"href":"/pix/adr/0006-ajout-du-support-de-sendinblue-pour-le-mailing/","title":"0006 Ajout Du Support De Sendinblue Pour Le Mailing","parent":"Adr","content":" 6. Ajout du support de SenInBlue pour l\u0026rsquo;e-mailing Date : 2020-01-28\nÉtat Accepted\nContexte Les DANE et académies ont tendance à bloquer les providers commerciaux et filtrent les messages avec un mécanisme de whitelisting d\u0026rsquo;IP.\nPar ailleurs, nous avons plusieurs fois rencontrés des difficultés avec MailJet (API limit, communication, support), en particulier lors de moments ou phases critiques.\nSans compter que MailJet a été racheté par MailGun, entreprise américaine. MailJet est donc désormais soumis au CLOUD Act.\nDécisions Pour passer le filtrage des académies, nous décidons de nous munir d\u0026rsquo;une IP fixe, que nous communiquons à nos partenaires.\nNous décidons de louer cette adresse IP chez un nouvel hébergeur, Sendinblue, éditeur français dont les données sont hébergées en France, et qui n\u0026rsquo;est pas a priori soumis au CLOUD Act.\nNous décidons d\u0026rsquo;implémenter un connecteur SendInBlue, sur le même modèle que le connecteur Mailjet : les infos du message dans le code, le template sur le site du provider.\nNous décidons de conserver le connecteur MailJet, au cas où nous serions déçu de SendInBlue, ou dans l\u0026rsquo;optique un jour d\u0026rsquo;implémenter un mécanisme de fallback.\nConséquences Ajout et modification des variables d\u0026rsquo;environnement suivantes :\nMAILING_PROVIDER : string [\u0026ldquo;mailjet\u0026rdquo; | \u0026ldquo;sendinblue\u0026rdquo;] MAILJET_API_KEY : string MAILJET_API_SECRET : string SENDINBLUE_API_KEY : string SENDINBLUE_ACCOUNT_CREATION_TEMPLATE_ID : string SENDINBLUE_ORGANIZATION_INVITATION_TEMPLATE_ID : string SENDINBLUE_PASSWORD_RESET_TEMPLATE_ID : string Liens Lien vers le schéma MailJet est soumis au CLOUD Act "},{"id":6,"href":"/pix/adr/0007-calcul-des-pix/","title":"0007 Calcul DES Pix","parent":"Adr","content":" 7. Calcul des pix Date : 2020-01-22\nÉtat Accepted\nContexte Le référentiel des Acquis et Compétences est actuellement stocké et géré dans Airtable.\nÀ chaque Acquis est associé une valeur en pix. Cette valeur est la résultante d\u0026rsquo;un calcul expliqué dans la documentation.\nDans le cadre de Pix+, des Acquis hors Compétences numériques sont ajoutés. Ces Acquis ne doivent pas influencer le nombre de pix gagné par l\u0026rsquo;utilisateur.\nDécision Le calcul pourrait être déplacée dans le datasource côté API, ce qui aurait pour conséquences de documenter et sécuriser le calcul via des tests unitaires.\nToutefois, il est décidé que l\u0026rsquo;effort que cela représente versus les gains apportés est trop important.\nNous décidons donc de faire évoluer le calcul dans Airtable.\nConséquences La formule de calcul ainsi que la documentation sont mises à jour.\nArchitecture D\u0026rsquo;un point de vue architecture logicielle, aucune évolution n\u0026rsquo;est nécessaire.\n"},{"id":7,"href":"/pix/adr/0008-d%C3%A9couplage-fonctionnel-via-evenements/","title":"0008 Découplage Fonctionnel via Evenements","parent":"Adr","content":" 8. Découplage de pans fonctionnels via évènements métier Date : 2020-03-27\nÉtat Cet ADR est étendu par l\u0026rsquo;ADR #10\nContexte Il y a une richesse métier spécifique importante qui gravite autour de la notion de \u0026ldquo;badge\u0026rdquo;:\nDéfinition d\u0026rsquo;un badge Conditions d\u0026rsquo;obtention d\u0026rsquo;un badge Persitence d\u0026rsquo;un badge Relation entre badges et certification \u0026hellip; La notion de \u0026ldquo;badge\u0026rdquo; intervient auprès de plusieurs pans fonctionnels (subdomains) déjà riches de logiques métier qui leur est propre :\nL\u0026rsquo;évaluation (on attribue un badge en fin de parcours) La certification (on vérifie l\u0026rsquo;obtention ou non d\u0026rsquo;un badge au moment de l\u0026rsquo;attribution d\u0026rsquo;une certification) On ne saurait rattacher entièrement la logique de \u0026ldquo;badge\u0026rdquo; ni au pan fonctionnel \u0026ldquo;Evaluation\u0026rdquo; ni au pan fonctionnel \u0026ldquo;Certification\u0026rdquo;.\nOn peut donc considérer \u0026ldquo;Badge\u0026rdquo; comme étant un pan fonctionnel (subdomain) à part entière.\nA ce titre, au niveau du code on cherchera à :\nMarquer clairement les frontières entre \u0026ldquo;Badge\u0026rdquo; et les autres contextes avec lesquels il interagit Centraliser et isoler la logique de badge pour ne pas qu\u0026rsquo;elle transpire dans celle des autres contextes et vice versa En jargon Domain-Driven Design (DDD), cela revient à faire correspondre un Bounded context au Subdomain \u0026ldquo;Badge\u0026rdquo;.\nDécision Utiliser des événements métier (domain events) pour la collaboration entre contextes.\nConséquences L\u0026rsquo;architecture applicative est legèrement différente.\nArchitecture Voici l\u0026rsquo;implémentation à date du usecase complete-assessment:\nmodule.exports = async function completeAssessment({ assessmentId, assessmentRepository, assessmentResultRepository, certificationCourseRepository, competenceMarkRepository, scoringCertificationService, }) { const assessment = await assessmentRepository.get(assessmentId); if (assessment.isCompleted()) { throw new AlreadyRatedAssessmentError(); } assessment.setCompleted(); if (assessment.isCertification()) { await _calculateCertificationScore({ assessment, assessmentResultRepository, certificationCourseRepository, competenceMarkRepository, scoringCertificationService }); } await assessmentRepository.completeByAssessmentId(assessmentId); return assessment; }; Pour y ajouter la sauvegarde du badge conditionnelle en fonction des résultats, on aurait pu ajouter ce bloc de code :\nif (assessment.isSmartPlacement()) { const badge = await badgeRepository.findOneByTargetProfileId(assessment.campaignParticipation.campaign.targetProfileId); if (badge != null) { const campaignParticipationResult = await campaignParticipationResultRepository.getByParticipationId(assessment.campaignParticipation.id); const areBadgeCriteriaFulfilled = badgeCriteriaService.areBadgeCriteriaFulfilled({ campaignParticipationResult }); if (areBadgeCriteriaFulfilled) { await badgeAcquisitionRepository.create({ badgeId: badge.id, userId: userId }); } } } Cela revient à faire transpirer la logique propre au domain \u0026ldquo;Badge\u0026rdquo; dans la logique propre du domain \u0026ldquo;Evaluation\u0026rdquo;. Les deux seraient alors couplées.\nOn choisit de renvoyer un évènement AssessmentCompleted en sortie de usecase :\nmodule.exports = async function completeAssessment({ assessmentId, assessmentRepository, assessmentResultRepository, certificationCourseRepository, competenceMarkRepository, scoringCertificationService }) { const assessment = await assessmentRepository.get(assessmentId); if (assessment.isCompleted()) { throw new AlreadyRatedAssessmentError(); } if (assessment.isCertification()) { await _calculateCertificationScore({ assessment, assessmentResultRepository, certificationCourseRepository, competenceMarkRepository, scoringCertificationService }); } await assessmentRepository.completeByAssessmentId(assessmentId); return new AssessmentCompleted( assessment.userId, assessment.isSmartPlacement() ? assessment.campaignParticipation.campaign.targetProfileId : null, assessment.isSmartPlacement() ? assessment.campaignParticipation.id : null, ); }; Cet évènement est récupéré par le controller qui le transmet à un event handler (dont le rôle est de réagir à un domain event):\nasync completeAssessment(request) { const assessmentId = parseInt(request.params.id); const assessmentCompletedEvent = await usecases.completeAssessment({ assessmentId }); await badgeCreationHandler.handle(assessmentCompletedEvent); return null; } Ce domain handler est dédiée à la logique de création de badge:\nconst badgeCreationHandler = { handle: async function(event) { if (event.targetProfileId != null) { const badge = await badgeRepository.findOneByTargetProfileId(event.targetProfileId); if (badge != null) { const campaignParticipationResult = await campaignParticipationResultRepository.getByParticipationId(event.campaignParticipationId); const areBadgeCriteriaFulfilled = badgeCriteriaService.areBadgeCriteriaFulfilled({ campaignParticipationResult }); if (areBadgeCriteriaFulfilled) { await badgeAcquisitionRepository.create({ badgeId: badge.id, userId: event.userId }); } } } } } Ainsi le usecase complete-assessment ne sait rien de la logique d\u0026rsquo;acqusition de badges qu\u0026rsquo;il provoque. De la même façon, le handler d\u0026rsquo;acquisition de badges ne sait rien de la logique de complétion d\u0026rsquo;un parcours qui le déclenche. Les deux logiques métiers sont complètement découplées.\nRéférences Articles :\nhttps://docs.microsoft.com/fr-fr/dotnet/architecture/microservices/microservice-ddd-cqrs-patterns/domain-events-design-implementation http://udidahan.com/2008/08/25/domain-events-take-2/ https://lostechies.com/jimmybogard/2010/04/08/strengthening-your-domain-domain-events/ https://lostechies.com/jimmybogard/2014/05/13/a-better-domain-events-pattern/ https://matthiasnoback.nl/2015/01/from-commands-to-events/ https://martinfowler.com/articles/201701-event-driven.html https://martinfowler.com/eaaDev/EventNarrative.html#HandlingEvents https://martinfowler.com/eaaDev/EventCollaboration.html Livres :\nObject Design Style Guide, chapitre 7.2 : Limit the scope of a command method, and use events to perform secondary tasks Implementing Domain-Driven Design, chapitre 8 : Domain Events Patterns, Principles and Practices of DDD, chapitre 18 : Domain Events "},{"id":8,"href":"/pix/adr/0009-transaction-metier/","title":"0009 Transaction Metier","parent":"Adr","content":" 9. Transactions métier Date : 2020-03-27\nÉtat Amendé par 0023-précision-sur-les-transactions-et-les-événements-métier.md.\nContexte Le mécanisme de transaction permet de garantir qu\u0026rsquo;une suite d\u0026rsquo;effets de bord n\u0026rsquo;a lieu que si chacun d\u0026rsquo;entre eux réussit. Si l\u0026rsquo;un des effets de bord échoue, aucun des autres effets ne sera appliqué.\nA date, on ne sait travailler avec les transactions qu\u0026rsquo;au niveau repositories. Dans le même repository, on sait par exemple écrire dans différentes tables en plusieurs étapes de façon transactionnelle.\nLimiter la gestion des transactions au niveau repository pose plusieurs problèmes :\nAppel de plusieurs repositories au sein d\u0026rsquo;un même usecase completeAssessment({assessment, assessmentRepository, badgeRepository}) { if (!assessment.isComplete()) { await assessmentRepository.completeByAssessmentId(assessment.id); // S\u0026#39;exécute sans problème await badgeRepository.acquireBadge(); // Échoue } } Dans l\u0026rsquo;exemple ci-dessus, les données de la base seront dans un état inconsistant. Le parcours sera flaggé comme terminé alors que l\u0026rsquo;enregistrement du badge à échouer.\nOr on ne sait pas :\nDétecter cette anomalie Rejouer l\u0026rsquo;acquisition du badge sans rejouer la complétion du parcours Design des objets métier / repositories par l\u0026rsquo;axe chronologique Pour palier à ce problème là, on pourrait déléguer la transaction à un seul repository:\ncompleteAssessment({assessment, assessmentRepository}) { if (!assessment.isComplete()) { assessment.badge = new Badge(); await assessmentRepository.completeAssessment(assessment); } } Cela amène à regrouper des objets par chronologie : l\u0026rsquo;assessment et le badge sont modifiés au même moment donc on les regroupe. Or cette solution amène du couplage entre deux aspects fonctionnels distincts qu\u0026rsquo;on voudrait pouvoir faire vivre et évoluer indépendamment.\nDécision Englober le usecase dans une transaction métier.\nConséquences L\u0026rsquo;architecture applicative est légèrement différente.\nArchitecture DomainTransaction class DomainTransaction { constructor(knexTransaction) { this.knexTransaction = knexTransaction; } static execute(lambda) { return knex.transaction((trx) =\u0026gt; { return lambda(new DomainTransaction(trx)); }); } } Controller async completeAssessment(request) { const assessmentId = parseInt(request.params.id); await DomainTransaction.execute(async (domainTransaction) =\u0026gt; { await usecases.completeAssessment({ domainTransaction, assessmentId }); }); return null; } Usecase j\ncompleteAssessment({assessment, domainTransaction, assessmentRepository, badgeRepository}) { if (!assessment.isComplete()) { await assessmentRepository.completeAssessment(assessment.id, domainTransaction); await badgeRepository.acquireBadge(domainTransaction); } } Repository completeByAssessmentId(assessmentId, domainTransaction = DomainTransaction.emptyTransaction()) { const assessment = await BookshelfAssessment .where({ assessmentId }) .save({ Assessment.states.COMPLETED }, { require: true, patch: true, transacting: domainTransaction.knexTransaction }); return bookshelfToDomainConverter.buildDomainObject(BookshelfAssessment, assessment); } Handlers L\u0026rsquo;utilisation de DomainTransaction permet également de placer un usecase ainsi qu\u0026rsquo;un ou plusieurs handlers dans la même transaction:\nasync completeAssessment(request) { const assessmentId = parseInt(request.params.id); await DomainTransaction.execute(async (domainTransaction) =\u0026gt; { const assessmentCompletedEvent = await usecases.completeAssessment({ domainTransaction, assessmentId }); await badgeCreationHandler.handle(domainTransaction, assessmentCompletedEvent); }); return null; }, "},{"id":9,"href":"/pix/adr/0010-propager-domain-events-via-event-dispatcher/","title":"0010 Propager Domain Events via Event Dispatcher","parent":"Adr","content":" 10. Propager les Domain Events via un Event Dispatcher Date : 2020-06-04\nCet ADR étend l\u0026rsquo;ADR #8\nÉtat Amendé par 0023-précision-sur-les-transactions-et-les-événements-métier.md.\nContexte Actuellement, les Domain Events sont distribués au Event Handlers à la main dans le controller (orchestration). Ceci était une solution temporaire, on souhaite que les Domain Handlers puissent s\u0026rsquo;abonner à des Domain Events (chorégraphie).\nDécision Les Event Handlers définissent eux-mêmes le type de Domain Events auxquels ils réagissent. Un mécanisme de publisher/subscribers appelé EventDispatcher est instancié au moment de l\u0026rsquo;injection de dépendances. Tous les handlers sont abonnés aux Domain Events qui les regardent au moment de leur injection.\nConséquences Controller Avant :\nasync completeAssessment(request) { const assessmentId = parseInt(request.params.id); await DomainTransaction.execute(async (domainTransaction) =\u0026gt; { const assessmentCompletedEvent = await usecases.completeAssessment({ domainTransaction, assessmentId }); const certificationScoringEvent = await events.handleCertificationScoring({ domainTransaction, assessmentCompletedEvent }); await events.handleBadgeAcquisition({ domainTransaction, assessmentCompletedEvent }); await events.handleCertificationAcquisitionForPartner({ domainTransaction, certificationScoringEvent }); }); return null; } Après :\nasync completeAssessment(request) { const assessmentId = parseInt(request.params.id); await DomainTransaction.execute(async (domainTransaction) =\u0026gt; { const event = await usecases.completeAssessment({ domainTransaction, assessmentId }); await events.eventDispatcher.dispatch(domainTransaction, event); }); return null; } Injection de dépendances Pseudo-code illustratif:\nconst handlersToBeInjected = { handleBadgeAcquisition: require(\u0026#39;./handle-badge-acquisition\u0026#39;), handleCertificationScoring: require(\u0026#39;./handle-certification-scoring\u0026#39;), handleCertificationAcquisitionForPartner: require(\u0026#39;./handle-certification-partner\u0026#39;) }; function buildEventDispatcher() { const eventDispatcher = new EventDispatcher(); for (const handler of handlersToBeInjected) { eventDispatcher.subscribe(handler.eventType, inject(handler)); } return eventDispatcher; } module.exports = { eventDispatcher: buildEventDispatcher() } Tests de chorégraphie Il devient alors possible (et précieux à titre de non-régression) de tester la bonne mise en place des Event Handlers en testant les chaînages.\ndescribe(\u0026#39;Event Choreography | Score Partner Certification\u0026#39;, function() { it(\u0026#39;chains Certification Scoring and Partner Certification Scoring on Assessment Completed\u0026#39;, async () =\u0026gt; { // given const { handlerStubs, eventDispatcher } = buildEventDispatcherAndHandlersForTest(); const domainTransaction = Symbol(\u0026#39;a transaction\u0026#39;); const assessmentCompleted = new AssessmentCompleted(); const certificationScoringCompleted = new CertificationScoringCompleted({}); handlerStubs.handleCertificationScoring.withArgs({ domainTransaction, event:assessmentCompleted }).resolves( certificationScoringCompleted ); // when await eventDispatcher.dispatch(domainTransaction, assessmentCompleted); // then expect(handlerStubs.handleCertificationAcquisitionForPartner).to.have.been.calledWith({ domainTransaction, event:certificationScoringCompleted }); }); }); Références : https://medium.com/ingeniouslysimple/choreography-vs-orchestration-a6f21cfaccae "},{"id":10,"href":"/pix/adr/0011-organisation-fichier-trad/","title":"0011 Organisation Fichier Trad","parent":"Adr","content":" 11. Organisation des fichiers de traductions Date : 2020-07-09\nÉtat En cours d\u0026rsquo;expérimentation\nContexte L\u0026rsquo;application App de Pix va avoir une version anglaise. Pour cela, nous devons traduire les textes présents sur l\u0026rsquo;application mon-pix. Pour gérer la traduction, nous utilisons l\u0026rsquo;add-on Ember ember-intl. Les traductions sont disponibles au format JSON dans le dossier translations. Le fichier JSON de la langue française sera directement envoyé à notre traductrice.\nDécision Fichiers de traductions Les textes se trouvent dans des fichiers uniques fr.json/en.json.\nLes textes sont rangés par ordre alphabétique des clés de traduction.\nLes fichiers de traduction contiennent :\nUne partie common : tous les mots que l\u0026rsquo;on peut retrouver dans toutes les pages de Pix (ex: Pix, Annuler, Obligatoire), les mots liés à des composants réutilisés partout Une partie navigation : lien des menus, liens \u0026ldquo;Retour à l\u0026rsquo;accueil\u0026rdquo; Une partie api-error-messages : les traductions des erreurs remontées par l\u0026rsquo;API Une partie pour les pages pages : (ex : pages.list-certifications, pages.challenges) Dans la partie common :\nUne partie actions avec les actions disponibles à plusieurs endroits (Annuler, etc\u0026hellip;) Une partie fields avec les champs de formulaire utilisés à plusieurs endroits Dans chaque page :\nUn title avec le titre de la page (en premier dans les traductions de la page) Une partie actions représentant les actions/boutons possibles. Chaque action contient: un label: il s\u0026rsquo;agit du texte visible contenu dans le bouton un extra-information: il s\u0026rsquo;agit du texte contenu dans l\u0026rsquo;attribut html title Les clés de traduction utilisées doivent aider à comprendre le contexte de la phrase. Il se base sur l\u0026rsquo;intention et ne reprend pas forcément la terminologie des attributs html lorsque l\u0026rsquo;intention n\u0026rsquo;y est pas claire.\nLes variables doivent être écrites en kebab-case (ex : certification-header-title)\nTests Le setupIntl pour les tests d\u0026rsquo;intégration se fait dans setupIntegration pour les tests d\u0026rsquo;intégration Les tests ont pour local fr On ne test pas les traductions (le plugin vérifie la présence de la traduction) Build En cas d\u0026rsquo;absence de traduction dans un fichier, le build de l\u0026rsquo;application échoue.\nUtilisation du service de traduction Dates Pour gérer les dates (et les formats) : {{format-date this.certification.date format='L'}}. Les formats sont dans le fichier mon-pix/app/formats.js\nPour gérer les durées: {{moment-duration tutorial.duration}}, où:\ntutorial.duration contient la durée au format HH:mm:ss, moment-duration traduit ici la durée en toutes lettres (l\u0026rsquo;expression retourne par exemple \u0026ldquo;3 minutes\u0026rdquo;) Il est également possible de mettre le formattage directement au niveau de la traduction avec cette syntaxe: `\u0026ldquo;key\u0026rdquo;: \u0026ldquo;Mon texte à la date du {maDate, date, L} à {monHeure, time, hhmm}\nNe pas oublier d\u0026rsquo;indiquer les locales prises en charge dans le tableau moment.includeLocales du fihier mon-pix/config/environment.js\nParamètres Il est possible de passer des paramètres au helper t:\ndans le hbs: {{t \u0026#39;challenge.title\u0026#39; stepNumber=this.stepNumber totalChallengeNumber=this.totalChallengeNumber}} dans le js this.intl.t(\u0026#39;challenge.title\u0026#39;, { stepNumber, totalChallengeNumber }) dans le json: \u0026#34;challenge\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Épreuve {stepNumber} sur {totalChallengeNumber}\u0026#34; } Pluriels Pour gérer le pluriel : \u0026quot;description\u0026quot;: \u0026quot;{ daysBeforeReset, plural, =0 {0 day} =1 {1 day} other {# days} } left before reset.\u0026quot;\nPour les futures développements : Pour les développements à venir, les textes des maquettes doivent être envoyés aux traducteurs en avance. Dans le cas de retard dans les traductions :\nAjouter les textes dans fr.json Dans en.json, mettre une traduction anglaise (à vérifier en internet) Le fichier fr.json sera fourni aux traducteurs qui nous fourniront un nouveau en.json Références : https://ember-intl.github.io/ember-intl/ "},{"id":11,"href":"/pix/adr/0012-utiliser-ember-pour-le-developpement-d-applications-front/","title":"0012 Utiliser Ember Pour Le Developpement D Applications Front","parent":"Adr","content":" 12. utiliser-ember-pour-le-developpement-d-applications-front Date: 2020-07-13\nÉtat Accepted\nContexte Cette ADR est une \u0026ldquo;rétro-ADR\u0026rdquo; qui explique un choix effectué et mis en œuvre depuis 4 ans.\nPix a vu le jour une nuit de juin 2016, veille d\u0026rsquo;un Open Lab (grosse réunion avec des responsables de l\u0026rsquo;Éducation nationale, de l\u0026rsquo;Enseignement supérieur et autres DRH \u0026amp; DSI d\u0026rsquo;acteurs majeurs du CAC 40).\nLa toute première version de l\u0026rsquo;application se résumait à 2 simples pages HTML/CSS. L\u0026rsquo;objectif était de présenter un concept et démontrer une vision pour valider nos hypothèses métier, rassurer/engager un max de partenaires potentiels avec nous et enclencher une dynamique.\nLa présentation fut un franc succès et dans les jours qui ont suivis, il a fallu se poser la question de la suite : nos pratiques (c\u0026rsquo;était facile, XP, pratiques agiles + craft + Ops), l\u0026rsquo;infra, et surtout notre stack technique.\nÀ ce moment, l\u0026rsquo;équipe technique était composée de 2 développeurs full-stack. Nous avons longtemps réfléchi au framework à utiliser : Play Framework, React, Vue, Angular, Backbone, jQuery, Meteor.\nNos besoins / envies / espoirs à ce moment là étaient les suivants :\npermettre une approche orientée plateforme, avec un \u0026ldquo;bloc API\u0026rdquo; central, lequel serait consommé par plusieurs applications Web front ou mobile, qui pourraient être développées par n\u0026rsquo;importe quelle personne de n\u0026rsquo;importe quelle future équipe (nous n\u0026rsquo;avions pas encore d\u0026rsquo;organisation en Product Teams, mais c\u0026rsquo;était un élément de vision globale) selon des façons de faire uniforme permettre une expérience utilisateur réactive, donc un style d\u0026rsquo;architecture SPA ou hybride (qui n\u0026rsquo;en était qu\u0026rsquo;à ses prémisses) plutôt que SSR-only être au plus proche des concepts et standards du Web et des paradigmes de développement modernes (routage, gestion de l\u0026rsquo;état du système, sécurité, accessibilité, performance, etc.) être bien documenté reposer sur une communauté et d\u0026rsquo;un environnement actifs et de qualité (addons, outillage, forums, meetups, confs, etc.) démontrer une maturité (éviter le Hype Driven Development) présenter des garanties d\u0026rsquo;évolution et de maintenance Sans oublier, nos contraintes d\u0026rsquo;archi technologiques :\nLimiter les technologies et leur diversité privilégier des solutions JavaScript privilégier des solutions Open Source Parmi les contraintes que nous n\u0026rsquo;avons pas forcément retenues :\nmontée en compétence : nous estimions avoir suffisamment d\u0026rsquo;expérience dans le dev Web front-end le fait d\u0026rsquo;être appuyé par un GAFAM : bien mais pas vital Décision Suite à des premiers travaux exploratoires, nous avons éliminé Météor, Phénix et ELM. Nous avons estimé qu\u0026rsquo;ils ne correspondaient pas à nos besoins fonctionnels (pas besoin de temps réel ou de synchronisation multi-clients avancée) et que la montée en compétence serait un frein.\nNous avons alors pensé à Play Framework ou Spring Boot, que nous avions déjà eu l\u0026rsquo;occasion d\u0026rsquo;utiliser en production sur des gros projets et qui possédaient le côté rassurant qui nous avait manqué lors de nos expérimentations techniques avec les solutions précédentes. Mais ils ne couvraient pas plusieurs critères : architecture SPA, JavaScript, communauté, garanties d\u0026rsquo;évolution (à peine 1 release minor tous les 2 ans).\nNous nous sommes recentré sur les frameworks Web JS. Pour l\u0026rsquo;avoir vécu / subi, nous avons éliminé la solution vanilla JS, car elle ne permet pas de coller simplement aux standards du Web, qu\u0026rsquo;il y a un gros efforts de documentation ou encore car elle ne permet pas de bénéficier des dernières avancées technologiques comme la gestion d\u0026rsquo;un DOM virtuel ou d\u0026rsquo;un store d\u0026rsquo;état interne.\nNous avons éliminé les libraries ou frameworks trop anciens dont l\u0026rsquo;avenir semblait appartenir au passé : jQuery, Backbone, Marionnette.js.\nNous avons éliminé les technologies trop nouvelles ou d\u0026rsquo;estime : Aurelia, Durandal, Mithril.\nÀ partir de là, il nous restait : AngularJS / Angular, Ember, React et Vue.\nÀ cette époque, AngularJS (v1.x) était plutôt bien implanté, mais React avait déjà pris l\u0026rsquo;ascendant, notamment en terme de communauté et d\u0026rsquo;activité sur GitHub / NPM. L\u0026rsquo;équipe Google travaillait déjà depuis plusieurs mois sur Angular (v2.x+) et une version bêta était disponible. Malheureusement Google avait déjà annoncé une incompatibilité entre les 2 versions. Ajouté à cela une confiance rompue envers les technos et la gouvernance de frameworks Web Open Source par Google (cf. GWT, Dart, Polymer, etc.), nous avons éliminé AngularJS \u0026amp; Angular.\nReact était le framework le plus en vogue, mais nous avions un doute quant au \u0026ldquo;syndrôme Google\u0026rdquo;, à savoir oublier le passé et la communauté sur un coup de tête de l\u0026rsquo;équipe (chez Facebook) en charge du projet. Par ailleurs, il existait déjà le phénomène propre à la communauté React de proposer 10 solutions viables pour 1 problème donné (ex : Hooks, Redux, Mobx, etc.). Nous avions peur de ne pas parvenir à définir une stack unique et consistante entre les multiple projets front-end anvisagés. Enfin le fait de mettre du HTML et du CSS dans du JS ne nous a pas paru respecter les standards. Nous avons éliminé React.\nVue était le framework avec la plus forte progression en terme de hype. Nous avons été très agréablement surpris par la simplicité de l\u0026rsquo;outil, sa qualité et de façon générale sa developer experience. Mais nous avons été refroidi par le fait qu\u0026rsquo;à l\u0026rsquo;époque, la lib reposait quasi-exclusivement sur 1 unique contributeur, sans gros sponsor ou référence derrière (hormis Alibaba.com). Nous avons éliminé Vue pour cette raison.\nFinalement, nous avons - encore une fois, il faut bien se remettre dans le contexte - retenu Ember.\nLes raisons qui nous ont convaincues à l\u0026rsquo;époque et qui restent d\u0026rsquo;actualité :\nle côté full-framework l\u0026rsquo;aspect conventions over configuration la réutilisabilité qui en découle (compatible avec une vision d\u0026rsquo;une architecture orientée plateforme) le CLI la maturité du framework (2009) par rapport à tous les autres la modernité (componentisation, Glimmer, SPA, SSR, PWA, etc.) la qualité du code la documentation Conséquences Nous avions anticipé certains écueils qui se sont malheureusement avérés :\nla montée en compétence longue et difficile sous bien des aspects (notamment le côté \u0026ldquo;conventions over configuration\u0026rdquo; qui est à double tranchant) la communauté plus restreinte que React, Vue et Angular et donc un défaut de documentation ou de plugins au goût du jour la gestion du state avec Ember Data le fait de devoir implémenter / respecter JSON API (si on ne veut pas s\u0026rsquo;attirer les foudres d\u0026rsquo;Ember #TrueStory) les tests applicatifs avec Mirage En revanche, dès lors que :\non respecte le framework on suit la doc on met régulièrement à jour les versions d\u0026rsquo;Ember on respecte les standards du Web on fait des tests automatisés on respecte les pratiques craft (bien nommer et découper son code, refactorer souvent, etc.) … on obtient des applications modernes de qualité qui, si elles ne sont pas les plus simples ou les plus amusantes à maintenir, permettent d\u0026rsquo;atteindre le million d\u0026rsquo;utilisateurs dans des conditions tout à fait acceptables.\n"},{"id":12,"href":"/pix/adr/0013-generer-des-fichiers-pdf/","title":"0013 Generer DES Fichiers Pdf","parent":"Adr","content":" 13. générer des fichiers pdf Date: 2020-09-24\nStatus Accepted\nContext L\u0026rsquo;attestation de la certification doit pouvoir être exportée au format PDF. Elle doit correspondre à la charte et permettre soit d\u0026rsquo;être imprimée, soit stockée (téléchargeable) en gardant les liens hypertextes actifs et la copie de texte (code de vérification). C\u0026rsquo;est pour le moment le seul document à exporter. Les différentes parties dynamiques sont :\nles infos personnelles du candidat le score les niveaux par compétence le code de vérification le badge cleA numérique (optionnel) Les domaines/competences sont fixes. Le seul élément qui va être vraiment variable sera le badge qui est optionnel.\nCette fonctionnalité est très attendue et va être suivie par des fortes échéances.\nLe fichier est téléchargé via un clic utilisateur et n\u0026rsquo;a pas besoin d\u0026rsquo;être généré automatiquement (cron etc)\nCe fichier sera téléchargeable depuis différentes applis PIX (pix app, orga\u0026hellip;)\nIl n\u0026rsquo;y a pas encore d\u0026rsquo;export PDF.\nDecision Possibilité 1 Les solutions pure front ont dû être vite écartées. Elles nécessiteraient de la duplication de code si le fichier est disponible sur plusieurs app et rendrait donc l\u0026rsquo;outil difficilement maintenable. Surtout que les bibliothèques qui transforment du html en pdf (html2canvas + pdfKit), font une capture \u0026ldquo;statique\u0026rdquo; du html (jpg) puis l\u0026rsquo;incluent dans un canvas sur le HTML. On perd donc la copie/recherche de texte, le lien hypertexte mais aussi des fonctionnalités avancées tel que la signature numérique du document. ⛔️ Cette solution a donc été tout de suite écartée.\nPossibilité 2 Les solutions SaaS telles que pdfgeneratorapi ou docraptor sont clé en main ce qui est très avantageux. En revanche l\u0026rsquo;aspect sécurité est un gros problème. Où sont stockées les données, les niveaux de sécurités sont ils adaptés ? Le coût est aussi un point négatif (on aura probablement 1 400 000 attestations qui pourraient être téléchargées sur l\u0026rsquo;année).\nPossibilité 3 Un premier POC a été fait avec puppeteer, une bibliothèque Node développée par google qui permet d\u0026rsquo;orchestrer un navigateur web (chrome/chromium) via le chrome dev-tools. Il est ainsi possible de charger une page web, soit via un url, soit via une page HTML et d\u0026rsquo;en faire un export PDF via l\u0026rsquo;API. Les avantages de cette solution sont :\ncôté API (réutilisabilité sur d’autres app front) utilisation de templates 100% custom et dynamiques (via template de lodash) les devs sont directement opérationnels (HTML+CSS) Les inconvénients de cette solution sont :\ncomplexifie l\u0026rsquo;infrastructure de l\u0026rsquo;environnement de production (installer puppeteer sur Scalingo demande à toucher l’OS déployé et géré par Scalingo) ------------------------------- api/.buildpacks ------------------------------- index 8c42335ce..2a6722a37 100644 @@ -1 +1,2 @@ https://github.com/Scalingo/nodejs-buildpack +https://github.com/jontewks/puppeteer-heroku-buildpack.git créer un serveur à part serait une solution mais demande un coût de temps et argent une page html n\u0026rsquo;est pas optimisée pour un rendu imprimable (format fixe) Possibilité 4 Une solution auto-hébergée tel que jsReport a été considérée mais nécessite comme puppeteer un serveur à part pour des résultats dont nous ne sommes pas certains.\nPossibilité 5 Une bibliothèque Node qui va générer directement du PDF\nLes avantages :\npdf natif stabilité gestion des méta-données pas de bibliothèques native spécifique à installer, pas de changement d\u0026rsquo;infra Les inconvénients :\nprise en main difficile (pas du HTML) Plusieurs choix sont possibles :\nPdfKit Bibliothèque node mature, pas de merge de PDF\nPdfLib Bibliothèque node plus récente que pdfkit. On peut merger les pdf. ✅ Cette solution est retenue, elle permettra ainsi d\u0026rsquo;importer un PDF avec toutes les données fixes et ensuite d\u0026rsquo;insérer les valeurs dynamiques selon des coordonnées précises.\nConséquences Nous sommes conscients que le choix de la bibliothèque PdfLib peut s\u0026rsquo;avérer contre productif sur le long terme si le document est amené à être plus dynamique. Pour le moment il n\u0026rsquo;y a qu\u0026rsquo;un élément réellement variable (l\u0026rsquo;obtention ou non du badge cléA et il faut pour cela 2 templates PDF différents avec des coordonnées pour le code de vérification qui vont devoir être recalculées. Pour autant, il n\u0026rsquo;est pas nécessaire de créer un nouveau serveur, la solution semble plus stable au moins sur le court terme.\n"},{"id":13,"href":"/pix/adr/0013-gestion-erreurs-api-ihm/","title":"0013 Gestion Erreurs API Ihm","parent":"Adr","content":" 13. Gestion erreurs entre IHM et API Date: 2020-08-04\nÉtat Proposed\nContexte Point 1: Actuellement, l\u0026rsquo;utilisation de l\u0026rsquo;objet JsonApiError n\u0026rsquo;est pas uniforme. Exemple de retour d\u0026rsquo;erreur Bad Request JOI : on utilise les deux attributs code, et status pour envoyer le status HTTP.\nfailAction: (request, h, err) =\u0026gt; { const errorHttpStatusCode = 400; const jsonApiError = new JSONAPIError({ _status: errorHttpStatusCode.toString(),_ title: 'Bad request', detail: 'The server could not understand the request due to invalid syntax.', }); failAction: (request, h, err) =\u0026gt; { const errorHttpStatusCode = 400; const jsonApiError = new JSONAPIError({ _code: errorHttpStatusCode.toString(),_ title: 'Bad request', detail: 'The server could not understand the request due to invalid syntax.', }); Point 2: Le message renvoyé par l\u0026rsquo;API ne contient pas l\u0026rsquo;origine de la violation JOI.\nconst jsonApiError = new JSONAPIError({ status: errorHttpStatusCode.toString(), title: 'Bad request', detail: 'The server could not understand the request due to invalid syntax.', }); Point 3: Côté IHM, comme l\u0026rsquo;erreur est envoyée sous différentes représentations (Point 1) et ne contient pas le détail de l\u0026rsquo;erreur (Point 2) il est difficile de la traiter (on fait au cas par cas pour le moment, le traitement des erreurs n\u0026rsquo;est pas mutualisé / globalisé).\nPoint 4: Aujourd\u0026rsquo;hui, Côté IHM, nous avons plusieurs cas de figure :\nNe pas gérer l\u0026rsquo;erreur, et l\u0026rsquo;écran reste figé.\nasync _authenticateWithUpdatedPassword({ login, password }) { const scope = 'mon-pix'; try { await this.session.authenticate('authenticator:oauth2', { login, password, scope }); } catch (response) { this.authenticationHasFailed = true; } } Afficher un message générique pour tous les types d\u0026rsquo;erreurs.\nasync addOrganization(event) { event.preventDefault(); try { await this.model.save(); this.notifications.success('L’organisation a été créée avec succès.'); this.transitionToRoute('authenticated.organizations.get', this.model.id); } catch (error) { this.notifications.error('Une erreur est survenue.'); } } Afficher un message générique à l\u0026rsquo;utilisateur final pour tous les cas d\u0026rsquo;erreur peut le perturber et le diriger sur une mauvaise cause de l\u0026rsquo;erreur.\nExemple: Le message \u0026lsquo;identifiant incorrect\u0026rsquo; est affiché lors d\u0026rsquo;une indisponibilité temporaire de l\u0026rsquo;application a déjà poussé l\u0026rsquo;utilisateur à réinitialiser son mot de passe.\nSe baser sur le code HTTP, pour différencier les erreurs.\n_manageErrorsApi(firstError) { const statusCode = _.get(firstError, 'status'); this.errorMessage = this._showErrorMessages(statusCode); } _showErrorMessages(statusCode) { const httpStatusCodeMessages = { '400': API_ERROR_MESSAGES.BAD_REQUEST.MESSAGE, '401': API_ERROR_MESSAGES.LOGIN_UNAUTHORIZED.MESSAGE, '500': API_ERROR_MESSAGES.INTERNAL_SERVER_ERROR.MESSAGE, '502': API_ERROR_MESSAGES.INTERNAL_SERVER_ERROR.MESSAGE, '504': API_ERROR_MESSAGES.GATEWAY_TIMEOUT.MESSAGE, 'default': API_ERROR_MESSAGES.INTERNAL_SERVER_ERROR.MESSAGE, }; return this.intl.t(httpStatusCodeMessages[statusCode] || httpStatusCodeMessages['default']); } Point 5: Dans le cas de la PR https://github.com/1024pix/pix/pull/1727, nous souhaitons afficher des messages appropriés selon le scénario X. Ce qui nous amène à avoir plusieurs messages d\u0026rsquo;erreurs pour le même status HTTP. Détail: Le message à afficher est calculé côté IHM à cause de l\u0026rsquo;internationalisation. Pour ce faire, l\u0026rsquo;IHM récupère des informations non présentes côté client via l\u0026rsquo;erreur renvoyée par l\u0026rsquo;API.\nDécision Point 1:\nUtiliser la structure suivante partout dans le code:\n- status: the HTTP status code applicable to this problem, expressed as a string value. - code: an application-specific error code, expressed as a string value. - title: a short, human-readable summary of the problem that SHOULD NOT change from occurrence to occurrence of the problem, except for purposes of localization. Exemple pour les `BadRequest` : const jsonApiError = new JSONAPIError({ status: errorHttpStatusCode.toString(), title: 'Bad request', detail: err.details[0].message, }); Point 2:\nRenvoyer la violation JOI dans l\u0026rsquo;erreur: Exemple: detail: err.details[0].message au lieu de detail: 'The server could not understand the request due to invalid syntax.' Point 3:\nCentraliser la gestion des erreurs côté IHM. ( Fera l\u0026rsquo;objet d\u0026rsquo;une autre ADR ) Point 4:\nSe baser sur le code HTTP pour afficher des messages appropriés. Exemple ci-dessous pour le login:\n\u0026ldquo;api-error-messages\u0026rdquo;: { \u0026ldquo;bad-request-error\u0026rdquo;: \u0026ldquo;Les données que vous avez soumises ne sont pas au bon format.\u0026rdquo;, \u0026ldquo;internal-server-error\u0026rdquo;: \u0026ldquo;Une erreur interne est survenue, nos équipes sont en train de résoudre le problème. Veuillez réessayer ultérieurement.\u0026rdquo;, \u0026ldquo;login-unauthorized-error\u0026rdquo;: \u0026ldquo;L\u0026rsquo;adresse e-mail ou l\u0026rsquo;identifiant et/ou le mot de passe saisis sont incorrects.\u0026rdquo; },\nAPI_ERROR_MESSAGES: { BAD_REQUEST: { CODE: '400', MESSAGE: 'api-error-messages.bad-request-error' }, LOGIN_UNAUTHORIZED: { CODE: '401', MESSAGE: 'api-error-messages.login-unauthorized-error' }, INTERNAL_SERVER_ERROR: { CODE: '500', MESSAGE: 'api-error-messages.internal-server-error', }, BAD_GATEWAY: { CODE: '502', MESSAGE: 'api-error-messages.internal-server-error' }, GATEWAY_TIMEOUT: { CODE: '504', MESSAGE: 'api-error-messages.internal-server-error' }, } _manageErrorsApi(firstError) { const statusCode = _.get(firstError, 'status'); this.errorMessage = this._showErrorMessages(statusCode); } _showErrorMessages(statusCode) { const httpStatusCodeMessages = { '400': API_ERROR_MESSAGES.BAD_REQUEST.MESSAGE, '401': API_ERROR_MESSAGES.LOGIN_UNAUTHORIZED.MESSAGE, '500': API_ERROR_MESSAGES.INTERNAL_SERVER_ERROR.MESSAGE, '502': API_ERROR_MESSAGES.INTERNAL_SERVER_ERROR.MESSAGE, '504': API_ERROR_MESSAGES.GATEWAY_TIMEOUT.MESSAGE, 'default': API_ERROR_MESSAGES.INTERNAL_SERVER_ERROR.MESSAGE, }; return this.intl.t(httpStatusCodeMessages[statusCode] || httpStatusCodeMessages['default']); } Point 5:\nEnrichir la structure de l\u0026rsquo;objet error JSON API en restant conforme avec la spécification (json-api-error)[https://jsonapi.org/format/#errors]\nid: a unique identifier for this particular occurrence of the problem. links: a links object containing the following members: about: a link that leads to further details about this particular occurrence of the problem. status: the HTTP status code applicable to this problem, expressed as a string value. code: an application-specific error code, expressed as a string value. title: a short, human-readable summary of the problem that SHOULD NOT change from occurrence to occurrence of the problem, except for purposes of localization. detail: a human-readable explanation specific to this occurrence of the problem. Like title, this field’s value can be localized. source: an object containing references to the source of the error, optionally including any of the following members: pointer: a JSON Pointer [RFC6901] to the associated entity in the request document [e.g. \u0026quot;/data\u0026quot; for a primary data object, or \u0026quot;/data/attributes/title\u0026quot; for a specific attribute]. parameter: a string indicating which URI query parameter caused the error. meta: a meta object containing non-standard meta-information about the error. On avait déjà le status, title, detail. On propose de l\u0026rsquo;enrichir avec les attributs code, et l\u0026rsquo;objet meta.\nExemple ici: https://github.com/1024pix/pix/pull/1727/\nL\u0026rsquo;attribut code : va contenir un code compréhensible de l\u0026rsquo;erreur, violation de règle de gestion pour identifier facilement l\u0026rsquo;erreur. L\u0026rsquo;objet meta va contenir des informations spécifiques au use-case. Exemple : afficher un message calculé côté IHM avec des informations renvoyées dans l\u0026rsquo;objet.\n_showErrorMessageByCode(meta) { const ACCOUNT_WITH_EMAIL_ALREADY_EXIST_FOR_ANOTHER_ORGANIZATION = `Vous possédez déjà un compte Pix avec l’adresse e-mail ${meta.value}\u0026lt;br\u0026gt; Pour continuer, connectez-vous à ce compte ou demandez de l’aide à un enseignant.\u0026lt;br\u0026gt;(Code R11)`; const ACCOUNT_WITH_USERNAME_ALREADY_EXIST_FOR_ANOTHER_ORGANIZATION = `Vous possédez déjà un compte Pix utilisé avec l’identifiant ${meta.value}\u0026lt;br\u0026gt; Pour continuer, connectez-vous à ce compte ou demandez de l'aide à un enseignant.\u0026lt;br\u0026gt;(Code R12)`; const ACCOUNT_WITH_GAR_ALREADY_EXIST_FOR_ANOTHER_ORGANIZATION = 'Vous possédez déjà un compte Pix via l\\'ENT dans un autre établissement scolaire.\u0026lt;br\u0026gt; Pour continuer, contactez un enseignant qui pourra vous donner l’accès à ce compte à l\\'aide de Pix Orga.'; const ACCOUNT_WITH_EMAIL_ALREADY_EXIST_FOR_SAME_ORGANIZATION = `Vous possédez déjà un compte Pix utilisé dans votre établissement scolaire, avec l'adresse mail ${meta.value}.\u0026lt;br\u0026gt; Connectez-vous à ce compte sinon demandez de l'aide à un enseignant. (Code R31)`; const ACCOUNT_WITH_USERNAME_ALREADY_EXIST_FOR_THE_SAME_ORGANIZATION = `Vous possédez déjà un compte Pix utilisé dans votre établissement scolaire, avec un identifiant sous la forme ${meta.value}.\u0026lt;br\u0026gt; Connectez-vous à ce compte sinon demandez de l'aide à un enseignant. (Code R32)`; const ACCOUNT_WITH_GAR_ALREADY_EXIST_FOR_THE_SAME_ORGANIZATION = 'Vous possédez déjà un compte Pix via l\\'ENT dans votre établissement scolaire.\u0026lt;br\u0026gt; Connectez-vous à ce compte sinon demandez de l\\'aide à un enseignant. (Code R33)'; const errorsMessagesByCodes = { 'R11': ACCOUNT_WITH_EMAIL_ALREADY_EXIST_FOR_ANOTHER_ORGANIZATION, 'R12': ACCOUNT_WITH_USERNAME_ALREADY_EXIST_FOR_ANOTHER_ORGANIZATION, 'R13': ACCOUNT_WITH_GAR_ALREADY_EXIST_FOR_ANOTHER_ORGANIZATION, 'R31': ACCOUNT_WITH_EMAIL_ALREADY_EXIST_FOR_SAME_ORGANIZATION, 'R32': ACCOUNT_WITH_USERNAME_ALREADY_EXIST_FOR_THE_SAME_ORGANIZATION, 'R33': ACCOUNT_WITH_GAR_ALREADY_EXIST_FOR_THE_SAME_ORGANIZATION, 'default': this.intl.t(API_ERROR_MESSAGES.INTERNAL_SERVER_ERROR.MESSAGE), }; return (errorsMessagesByCodes[meta.displayShortCode] || errorsMessagesByCodes['default']); } Conséquences Point 1: Une seule représentation de l\u0026rsquo;objet Error permettra d\u0026rsquo;uniformiser le parsing des erreurs. Point 2: Renvoyer le detail de l\u0026rsquo;erreur JOI va aider le consommateur à corriger le problème et faire un nouvelle tentative. Point 3: Avoir une stratégie commune et centralisée des erreurs dans les applications Pix. Point 4: Une meilleure UX pour l\u0026rsquo;utilisateur final. Point 5: Pouvoir afficher différents messages pour le même code HTTP en se basant sur un code fonctionnel. "},{"id":14,"href":"/pix/adr/0014-utiliser-type-stockage-JSONB-base-de-donnees/","title":"0014 Utiliser Type Stockage JSON B Base De Donnees","parent":"Adr","content":" 14. Utiliser le type de données JSONB en base de données Date: 2020-11-20\nStatus Accepted\nContext Jusqu\u0026rsquo;ici, Pix n\u0026rsquo;utilise que des types de données primitifs de PostgreSQL (VARCHAR, TIMESTAMP, INTEGER). Lors de l\u0026rsquo;intégration du fournisseur d\u0026rsquo;identité (IDP) Pôle Emploi, il était nécessaire de stocker des propriétés qui, selon le contexte, pouvaient ne pas exister.\nPar exemple, les méthodes d\u0026rsquo;authentification liées à différents IDP sont\npour l\u0026rsquo;IDP local (Pix), 2 propriétés: mot de passe + le mot de passe est-il expiré pour l\u0026rsquo;IDP GAR, 1 propriété: identifiant Opaque (IDO/SAMLID) pour l\u0026rsquo;IDP Pôle Emploi, 1 propriété: Subject Identifier (sub) Il y a un besoin de recherche sur les propriétés suivantes\nidentifiant Opaque (IDO/SAMLID) Subject Identifier (SUB) Les 2 critères sont les suivants:\nmaintenabilité accès rapide lors de la recherche Possibilité 1 Garder les types de données natifs. Ajouter une colonne pour chacune des 4 propriétés. L\u0026rsquo;inconvénient majeur est la maintenabilité. Quand un développeur affiche le contenu de la table, il est difficile de:\nsavoir ce que représentent ces données; et donc de détecter des données incorrectes. Possibilité 2 Stocker toutes les propriétés au format de représentation JSON dans une seule colonne\nNous recherchons un format de stockage qui:\npermet de stocker des données au format de représentation JSON, ex { password: 'uhu@@LL^55', shouldChangePassword: false } ou { samlId: 'JKLO-555-HUHUHU } permet les recherches, ex dans knex where({ value:{ samlId: '455456FFF' } }) soit indexable CREATE UNIQUE INDEX authentication_methods_value_unique ON \u0026quot;authentication-methods\u0026quot;( (\u0026quot;value\u0026quot;-\u0026gt;\u0026gt;'samlId') ); Il existe 2 formats de stockage\nJSON: stocke les données au format texte JSONB: stocke les données au format binaire =\u0026gt; plus performant, permet l\u0026rsquo;indexation, recherche plus lisible Le format JSONB est le seul éligible vu nos exigences.\nDecision Combiner les deux solutions:\nPour profiter de la rapidité d\u0026rsquo;exécution connue des recherches sur les types de données natifs, possibilité 1:\nstocker les propriétés SAMLID et SUB dans une seule propriété, qui sera indexée Pour profiter de la flexibilité du stockage JSONB, possibilité 2:\nstocker les propriétés de l\u0026rsquo;IDP local (Pix) dans un type JSONB Note: il aurait été possible de voir si le type de données JSONB avec index permettait des recherches aussi rapides que sur un type primitif. Le compromis a été de ne pas investiguer cette voie, et de choisir la solution éprouvée, pour gagner du temps.\nConséquences Appliquer la décision\n"},{"id":15,"href":"/pix/adr/0015-stockage-du-referentiel-en-cache/","title":"0015 Stockage Du Referentiel en Cache","parent":"Adr","content":" 15. Modification du stockage en cache du référentiel de contenu Date : 2020-12-02\nÉtat Accepted\nContexte Suite à l‘utilisation d‘une route unique pour récupérer le référentiel de contenu dans la Pull Request 2224, il n‘est plus nécessaire de stocker 1 clé par type d‘objet dans le cache.\nDécision Afin de simplifier l‘usage, une clé unique LearningContent est utilisée pour stocker le référentiel dans le cache.\nLiens ADR de la mise en place du cache [Création du endpoint GET /current-content sur Pix LCMS] (https://github.com/1024pix/pix-editor/pull/67) "},{"id":16,"href":"/pix/adr/0016-utilisation-de-hasMany-dans-Ember/","title":"0016 Utilisation De Has Many Dans Ember","parent":"Adr","content":" 16. Utilisation de hasMany avec les filtres et pagination dans Ember Date : 2021-01-12\nÉtat Accepted\nContexte Lorsqu\u0026rsquo;on utilise hasMany dans un modèle Ember, Ember fait l\u0026rsquo;hypothèse qu\u0026rsquo;il manipule une collection complète. C\u0026rsquo;est la raison pour laquelle il n\u0026rsquo;existe pas de méthode query sur les relations hasMany.\nLe problème des hasMany filtrés/paginés est que la collection associée se retrouve à ne pas contenir un reflet fiable de ce que contient la base mais une vue arbitrairement limitée en fonction des paginations/filtres qui viennent d\u0026rsquo;être faits.\nPar conséquent, le code qui fait une hypothèse différente se retrouve induit en erreur.\nDécision Aucune collection nécessitant d\u0026rsquo;être filtrée et ou paginée ne doit être une relation de type hasMany, mais un modèle classique que l\u0026rsquo;on récupère via la méthode query. Il faut donc écrire la méthode urlForQuery dans l\u0026rsquo;adapter.\nLiens Exemple de refactoring supprimant une relation hasMany Exemple de méthode urlForQuery "},{"id":17,"href":"/pix/adr/0018-specifier-version-nodejs/","title":"0018 Specifier Version Nodejs","parent":"Adr","content":" 1. Spécifier la version de NodeJS Date : 2020-01-18\nÉtat Accepté\nContexte Sur ce projet, nous avons besoin de :\nsavoir quelle version de NodeJS est utilisée sur chaque environnement (intégration, recette, production) garantir une stabilité de la plateforme, en intégrant les versions les plus à jour, testées Il existe un mécanisme natif pour indiquer la version souhaitée\nnominal, dans la section engines des fichiers package.json local, ex dans le fichier .nvmrc CI, dans la section image du fichier .circleci/config.yml Cette spécification de version existe en 2 syntaxes, ainsi deux solutions s\u0026rsquo;offrent à nous :\nSpécifier le numéro de version complet jusqu\u0026rsquo;au patch (ex : 1.2.3), ce qui permet\nd\u0026rsquo;utiliser la même version de NodeJS sur l\u0026rsquo;ensemble des contextes (local, CI, PAAS) d\u0026rsquo;utiliser la même version de NodeJS sur l\u0026rsquo;ensemble des applications Spécifier un intervalle de version jusqu\u0026rsquo;à la majeure (ex : 1.x.x), ce qui permet\nd\u0026rsquo;automatiser les montées de version (délégué au gestionnaire de version local, CI, PAAS) Spécifier un numéro de version complet Cette solution consiste à spécifier le numéro de version complet jusqu\u0026rsquo;au patch (ex: 1.2.3).\nElle\nest compréhensible par tous les développeurs offre la maitrise complète sur la release (seul un développeur déclenche une montée de version) Spécifier un intervalle de version Implémentation PAAS Spécifier un intervalle de version (ex jusqu\u0026rsquo;à la majeure : 1.x.x) dans le package.json Le PAAS assure un service de résolution des intervalles lors du Build (ex : semver.io)\nLocal Spécifier un intervalle de version dans le fichier .nvmrc Le gestionnaire de version utilise le package semver, différent du service de résolution que le PAAS (semver.io)\nCI S\u0026rsquo;assurer que\nla CI dispose de tags vers des images Docker ces tags sont équivalents à l\u0026rsquo;intervalle de version Par exemple, le tag CircleCI lts pointe vers la dernière version de la release LTS.\nCependant, il y a plusieurs dépendances à satisfaire :\nla version de NodeJS dans l\u0026rsquo;image API (équipe CircleCI) la version de NodeJS dans l\u0026rsquo;image Front (équipe CircleCI) la version de NodeJS dans l\u0026rsquo;image du navigateur des tests E2E (équipe Cypress) Cela implique que, lors de la publication d\u0026rsquo;une nouvelle version par les mainteneurs de NodeJS, un délai s\u0026rsquo;écoule jusqu\u0026rsquo;à ce que ces deux équipes aient testé et publié ces deux images. Pendant ce temps, la version sur le PAAS et la CI ne sont plus synchronisées. Dans le cas de Cypress, le délai avant publication d\u0026rsquo;une nouvelle image est de l\u0026rsquo;ordre de plusieurs semaines.\nBilan Avantages :\npermet d\u0026rsquo;utiliser les nouvelles versions au plus tôt permet d\u0026rsquo;utiliser les nouvelles versions sans intervention manuelle Inconvénients :\nest moins compréhensible (nécessite de faire la résolution de version) n\u0026rsquo;offre pas la maitrise complète sur la release (la version change dès publication d\u0026rsquo;une version de l\u0026rsquo;intervalle) expose à des désynchronisations de version Décision Les critères suivants sont plébiscités :\nsimplicité de compréhension caractère volontaire de la montée de version En conséquence, nous spécifions le numéro de version complet jusqu\u0026rsquo;au patch (ex : 1.2.3)\nVoir aussi la discussion de la PR 2360\nConséquences A chaque nouvelle version de NodeJS éligible, notamment les corrections de sécurité, spécifier la version complète.\nEn complément, utiliser le package check-engine sur le hook d\u0026rsquo;installation pour refuser l\u0026rsquo;installation des packages si la version de NodeJS n\u0026rsquo;est pas celle attendue\n\u0026#34;preinstall\u0026#34;: \u0026#34;npx check-engine\u0026#34;, "},{"id":18,"href":"/pix/adr/0019-typer-les-identifiants/","title":"0019 Typer Les Identifiants","parent":"Adr","content":" 19. Typer les identifiants Date : 2020-27-01\nÉtat Accepté\nContexte Sur ce projet, nous avons besoin de :\néviter les incohérences en contrôlant la validité des données, notamment des identifiants pouvoir consulter les types de données (ex: lors des phases de design) dans un seul endroit isoler le domaine, notamment de l\u0026rsquo;implémentation des identifiants dans les data-provider cache BDD propre ou distante (LCMS) permettre le changement de type disposer de plusieurs types, suivant les exigences d\u0026rsquo;implémentation Cela ne veut pas dire que :\nle domaine fixe arbitrairement le type, car il risque de ne pas pouvoir être implémenté dans les data-provider le domaine impose un format de sérialisation à l\u0026rsquo;interface REST entre un front et l\u0026rsquo;API Nous souhaitons plutôt que :\nle domaine contienne la description des types d\u0026rsquo;identifiant les données manipulées puissent être contrôlées par rapport à cette description Solution n°1 : contrôler le type côté domaine Il est possible de contrôler la validité des données fournies lors de l\u0026rsquo;instanciation des objets du domaine. Ce contrôle peut être effectué par une libraire dédiée, par exemple Joi.\nIl est aussi possible de le faire en utilisant au lieu du langage Javascript le language TypeScript. Dans ce cas, la vérification de type (type checking) est déléguée au langage.\nAvantages :\nmet le domaine au centre si un langage typé est choisi, prévient les erreurs d\u0026rsquo;inattention Inconvénients :\nperformance moindre, car un identifiant incorrect traversera toutes les couches avant d\u0026rsquo;être rejeté si un langage typé est choisi, coût d\u0026rsquo;implémentation élevé (réécriture et formation des développeurs) Solution n°2 : contrôler le type côté application Il est également possible de contrôler la validité des données fournies en entrée de l\u0026rsquo;API avec une librairie dédiée. Cela n\u0026rsquo;est pas strictement de la responsabilité de la couche application. Néanmoins, sous l\u0026rsquo;hypothèse que toutes les données déjà persistées sont conformes au modèle, et en l\u0026rsquo;absence d\u0026rsquo;erreur dans le code, cela suffit à garantir que le type des données (ici, des identifiants) est conforme.\nBien que la vérification ne soit pas effectuée dans le domaine, la définition du type peut appartenir au domaine.\nAvantages :\ncoût d\u0026rsquo;implémentation moins élevé (librairie Joi déjà connue, et solution déjà partiellement en place) performance plus élevée, car un identifiant incorrect sera rejeté avant d\u0026rsquo;être passé au controller Inconvénients :\nle controller effectue une opération qui n\u0026rsquo;est pas de sa responsabilité première Décision Au vu des coûts d\u0026rsquo;implémentation, le solution n° 2 est retenue.\nConséquences Dans le domaine, décrire les types d\u0026rsquo;identifiants du domaine en fonction de leur implémentation\nconst implementationType = { positiveInteger32bits: Joi.number().integer().min(postgreSQLSequenceDefaultStart).max(postgreSQLSequenceEnd).required(), alphanumeric255: Joi.string().max(255).required(), }; const campaignId = implementationType.positiveInteger32bits; const userId = implementationType.positiveInteger32bits; N\u0026rsquo;exposer que les types du domaine\nmodule.exports = { campaignId, userId, }; En entrée de la route, contrôler la conformité de la donnée reçue par rapport au type du domaine\nconst identifiersType = require(\u0026#39;../../domain/types/identifiers-type\u0026#39;); method: \u0026#39;GET\u0026#39;, path: \u0026#39;/api/users/{userId}/campaigns/{campaignId}/profile\u0026#39;, config: { validate: { params: Joi.object({ userId: identifiersType.userId, campaignId: identifiersType.campaignId, }), }, Ne pas écrire de test d\u0026rsquo;intégration sur ce contrôle\n"},{"id":19,"href":"/pix/adr/0020-caractere-obligatoire-use-case/","title":"0020 Caractere Obligatoire Use Case","parent":"Adr","content":" 20. Est-il obligatoire d\u0026rsquo;implémenter un use-case dans toutes les situations ? Date : 2020-01-25\nÉtat Adopté\nContexte Il existe dans le repository des use-case réduits à un appel de dépendance.\nmodule.exports = function getTargetProfileDetails({ targetProfileId, targetProfileWithLearningContentRepository }) { return targetProfileWithLearningContentRepository.get({ id: targetProfileId }); }; Nous avons besoin de savoir s\u0026rsquo;il faut systématiquement créer un use-case, même s\u0026rsquo;il ne contient qu\u0026rsquo;un seul appel à la dépendance injectée.\nSolution n°1 : Ne pas créer systématiquement un use-case par route Avantages :\nmoins verbeux : deux fichiers de moins (implémentation + test) Inconvénients :\narbitrage à effectuer à chaque modification de la route : faut-il extraire le code du controller dans un use-case ? Solution n°2 : Créer systématiquement un fichier sous le dossier use-case Avantages :\npas de réflexion sur la nécessité de créer un use-case Inconvénients :\nplus verbeux Décision La solution n°2 est adoptée\nConséquences Toutes les routes créées feront appel à un use-case. Pas de reprise systématique de l\u0026rsquo;existant.\n"},{"id":20,"href":"/pix/adr/0021-gravitee-pix-apim/","title":"0021 Gravitee Pix Apim","parent":"Adr","content":" 21. Choix d\u0026rsquo;un API manager Date : 2020-02-26\nÉtat Adopté\nContexte Dans le cadre de l’interconnexion avec les systèmes Livret scolaire (LSU/LSL) via API, Pix avait besoin de garantir les points ci-dessous:\nSécuriser l\u0026rsquo;échange entre les deux SI Offrir un portail de documentation de l\u0026rsquo;API Offrir plusieurs environnements (sandbox/production) Avoir une traçabilité des appels Respecter les contraintes RGPD Échange/stockage des données sur le réseau Français Solution 1 : Gravitee.io Avantages :\nRemplit les critères de choix de l\u0026rsquo;APIM de PIX :\n✅ Made in France ✅ Un déploiement on premise (via scalingo) ✅ Open Source, Éviter un vendor lock-in ✅ Performance de la gateway ✅ Scalabilité horizontale ✅ Traçabilité avec un respect RGPD ❌ Intégration Datadog Gravitee.io permet le paramétrage des APIs :\nGestion authentification (API Key, Keyless, Group / Members Access, Identity Provider) Documentation des APIs à partir de spécification OpenAPI Mise en place du mode CORS Mise en place de rate limit, quotas Mise en place de règles spécifiques pour l’API, filtrable par url, méthode http Mise en place de caches avec durée de vie Mise en place de notifications au support selon plusieurs critères (Email, Portal notification, Appel http) Inconvénients :\nPas d\u0026rsquo;intégration avec Datadog, Gravitee nécessite ElasticSearch pour l\u0026rsquo;analytique et le monitoring Avantage :\nGravitee est déjà utilisé par de nombreuses administrations dont LSU et LSL font partie. Solution 2 : Kong CE Avantages :\nRemplit les critères de choix de l\u0026rsquo;APIM de PIX :\n❌ Made in France ✅ Un déploiement on premise (via scalingo) ✅ Open Source (Gateway) ❌ Pas de vendor lock-in ✅ Performance de la gateway ✅ Scalabilité horizontale ✅ Traçabilité avec un respect RGPD ✅ Intégration Datadog Kong permet le paramétrage des APIs :\nGestion authentification (API Key, Keyless, Group / Members Access, Identity Provider) Documentation des APIs à partir de spécification OpenAPI Mise en place du mode CORS Mise en place de rate limit, quotas Mise en place de règles spécifique pour l’API, filtrable par url, méthode http Mise en place de caches avec durée de vie Mise en place de notifications au support selon plusieurs critères (Email, Portal notification, Appel http) Décision Gravitee a été choisi comme solution d\u0026rsquo;APIM pour Pix.\nConséquences Dans un premier temps, les APIs du livret scolaire seront accessibles via la gateway de Gravitee. Une généralisation de toutes les APIs partenaires de Pix est prévue dans un second temps.\n"},{"id":21,"href":"/pix/adr/0022-gestion-des-images-dans-app/","title":"0022 Gestion DES Images Dans App","parent":"Adr","content":" 22. Gestion des images dans APP Date : 2021-03-03\nÉtat En cours\nContexte Le site APP de Pix possède de nombreuses images, logos, illustrations. Ces derniers sont rangés dans /mon-pix/public/images. Ce dossier Images, au fil du temps, a commencé à être en désordre. Il est difficile de voir les images présentes, et de nombreuses images obsolètes sont encore présentes.\nDécisions Afin d\u0026rsquo;éviter le désordre et pour retrouver plus facilement des images similaires, la première décision est de créer des sous-dossiers :\n/background : images utilisées en fond de texte, purement décoratives /icons : les icones, images petites pour donner une information (possiblement remplaçable par FontAwesome) /illustrations : des images plus grandes pour décorer ou pour donner des informations plus complexes /logos : les logos de Pix ou de partenaires Ces sous-dossiers peuvent contenir d\u0026rsquo;autres sous-dossiers pour des regroupements particuliers : par exemple, un dossier tutorial pour toutes les illustrations du didacticiel.\nLes SVG doivent aussi suivre ces règles :\nAvoir un title dans le svg : il servira de title de l\u0026rsquo;image et pourra être lu par les lecteurs vocaux. Avoir un desc dans le svg si ce dernier contient de nombreuses informations : une description textuelle doit être ajoutée Utiliser l\u0026rsquo;outil svgo (avec la commande svgo image.svg) pour optimiser le SVG Conséquences Les nouvelles images seront rangées de manière logique ; Cela évitera d\u0026rsquo;importer des images en doublon et de ne pas utiliser notre bibliothèque d\u0026rsquo;images existantes ; Les SVG seront plus accessibles et plus optimisés. "},{"id":22,"href":"/pix/adr/0023-suppression-du-support-mailjet-pour-le-mailing/","title":"0023 Suppression Du Support Mailjet Pour Le Mailing","parent":"Adr","content":" 23. Suppression du support Mailjet pour le mailing Date : 2021-02-26\nÉtat Accepted\nContexte Le service de mailing MailJet n\u0026rsquo;est plus utilisé.\nOutre le fait que le code ne soit plus utile, le package lié n\u0026rsquo;est plus maintenu depuis 2 ans et cause l\u0026rsquo;affichage de warnings.\nBien sûr, n\u0026rsquo;étant plus utilisé, il n\u0026rsquo;y a pas de risque sur ce package.\nMais comme le développeur ne peut pas le vérifier aisément, cela risque de cacher de vrais risques sur le code restant.\nNous avions décidés de conserver le connecteur MailJet, au cas où nous serions déçu de SendInBlue, ou dans l\u0026rsquo;optique un jour d\u0026rsquo;implémenter un mécanisme de fallback.\nDécisions Supprimer notre dépendance à Mailjet.\nConséquences En cas de défaillance grave de SendInBlue, on ne peut pas changer de provider de mailing.\nOn pourra donc résilier le service Mailjet.\n"},{"id":23,"href":"/pix/adr/0024-encapsuler-appel-http/","title":"0024 Encapsuler Appel HTTP","parent":"Adr","content":" 24. Faut-il encapsuler les appels http dans l\u0026rsquo;API ? Date : 2020-04-22\nÉtat Adopté\nContexte L\u0026rsquo;API effectue des appels http:\nvers des services Pix (ex: LCMS); vers des API externes à Pix (ex: Pole Emploi). La librairie standard node permet de faire des appels http avec http.request().\nIl existe des librairies bâties au-dessus de la librairie standard, qui offrent :\nune interface (API) simplifiée (ex: pour traiter une réponse, la librairie standard prend en argument un callback et émet des évènements, alors que axios renvoie une promesse); des fonctionnalités supplémentaires. La plupart des contributeurs de ces librairies sont bénévoles. Il y a donc un risque que leur maintenance ne soit un jour plus assurée. De plus, toutes n\u0026rsquo;offrent pas les mêmes fonctionnalités.\nPour ces deux raisons, nous pourrions être amenés à vouloir changer de librairie. Dans ce cas, le coût de migration (réécriture du code) est un facteur à prendre en compte.\nCette encapsulation a déjà été réalisée sur le logging avec logger. À la question \u0026ldquo;Quels sont les cas pertinents pour encapsuler ?\u0026rdquo;, les appels http sont régulièrement cités.\nSolution n°1 : Encapsuler les appels à la librairie http dans un composant Un composant, http-agent, appelle la librairie (ex: axios).\nLe code de production fait appel à ce composant uniquement pour tout appel http.\nAvantages :\ndiminution du coût de migration: seul ce composant doit être modifié. Inconvénients :\nle développeur doit retenir l\u0026rsquo;usage et le nom et du composant (ce coût est partiellement mitigeable avec de la documentation et des règles de lint, mais ne peut être totalement supprimé) ; le développeur doit retenir son API et le mapping avec la librairie appelée. Solution n°2 : Appeler directement la librairie Le code de production fait directement appel à la librairie.\nAvantages :\nmontée en compétences facilitée : le développeur connait probablement déjà la librairie de par ses expériences précédentes Inconvénients :\naugmentation du coût de migration : tous les appels doivent être modifiés Décision La solution n°1 est adoptée\nConséquences En dehors des API externes proposant une librairie dédiée (ex: mailjet), appeler le composant http-agent à la place de la librairie (ex: axios).\nAjouter une règle de lint pour empêcher l\u0026rsquo;usage direct et non-intentionnel de la librairie (ex: axios).\n"},{"id":24,"href":"/pix/adr/0025-precisions-sur-les-transactions-et-les-evenements-metier/","title":"0025 Precisions Sur Les Transactions Et Les Evenements Metier","parent":"Adr","content":" 25. Précision sur les transactions et les événements métier État Amende 0009-transaction-metier.md et 0010-propager-domain-events-via-event-dispatcher.md.\nContexte On a eu plusieurs fois le problème d\u0026rsquo;avoir une instance de production qui deadlock complètement son pool de connexions SQL à cause d\u0026rsquo;une requête dans une transaction qui attend la fin d\u0026rsquo;une requête hors transaction qui elle-même attend que la requête qui a démarré la transaction libère sa connexion.\nLe problème est décrit dans cette page de wiki :\nhttps://1024pix.atlassian.net/wiki/spaces/DEV/pages/2504065029/Bloquage+du+pool+de+connection+sur+les+transactions Des PRs qui documentent le problème :\nBUGFIX: Modifier la sauvegarde du temps sur l\u0026rsquo;assessment BUGFIX: Le mésusage de la DomainTransaction provoque des deadlocks dans le flux de complétion d\u0026rsquo;asssessment (PIX-2457) Sur ces PRs, ce qu\u0026rsquo;on constate c\u0026rsquo;est qu\u0026rsquo;il n\u0026rsquo;est pas évident que tout code qui est mis dans une callback de DomainTransaction doive faire l\u0026rsquo;intégralité de ses requêtes SQL à l\u0026rsquo;intérieur de la même transaction. De déroger à cette règle risque de provoquer une suite de deadlocks et de vider le pool de requêtes d\u0026rsquo;instances en cas de forte charge sur la plateforme.\nOn constate aussi qu\u0026rsquo;il est difficile de savoir si utiliser des Domain Events est possible en dehors d\u0026rsquo;une DomainTransaction.\nDécision Au vu des informations ci-dessus, et comme les events sont un outil de découplage, on décide de ne plus utiliser les events à l\u0026rsquo;intérieur de domain transaction ni de transactions.\nConséquences Les événements ne doivent pas servir à enchaîner des traitements qui doivent échouer ensemble ou réussir ensemble, ils doivent être utilisés pour des enchaînements moins liés.\nAucun rollback fourni par la BDD en cas d\u0026rsquo;erreur de traitement d\u0026rsquo;un événement Si les traitements d\u0026rsquo;événements ne sont plus dans une transaction, alors l\u0026rsquo;échec de traitement d\u0026rsquo;un événement n\u0026rsquo;entrainera plus le rollback automatique des traitements qui ont déclenché cet événement.\nLes traitements qui doivent échouer ou réussir ensemble ne doivent plus utiliser d\u0026rsquo;événements Conséquence de ce qui précède, si quand un traitement échoue il doit entrainer un rollback du traitement précédent, alors le usecase qui les orchestre ne peut plus utiliser un mécanisme de dispatch d\u0026rsquo;événement.\nExemple de traitements qui doivent échouer ou réussir ensemble dans le usecase qui orchestre la complétion d\u0026rsquo;un assessment :\nL\u0026rsquo;assessment est marqué comme terminé, et sa date de complétion est enregistrée Si l\u0026rsquo;assessment ne correspond pas à un test de certification, si des badges ont été acquis, l\u0026rsquo;acquisition des badges est sauvegardée. Si l\u0026rsquo;assessment correspond à un test de certification, le score de certification est calculé puis sauvegardé. Appliquer cette décision dans le code Il faut appliquer cette décision dans le code, par exemple le usecase complete-assessment ne suit pas (encore) cette décision.\nPour les traitements qui doivent échouer ou réussir ensemble et qui utilisent aujourd\u0026rsquo;hui de la chorégraphie par événements dans une transaction : conserver la transaction et remplacer cette chorégraphie par événements par une orchestration sans événements.\nPour les traitements qui peuvent échouer ou réussir indépendamment et qui utilisent une chorégraphie par événements à l\u0026rsquo;intérieur d\u0026rsquo;une transaction, supprimer la transaction.\nCe qui n\u0026rsquo;est pas traité par cette ADR Pour cette dernière option, on peut se poser la question suivante : \u0026ldquo;Comment on gère les échecs de l\u0026rsquo;un ou l\u0026rsquo;autre des traitements?\u0026rdquo;\nOn peut imaginer une voie future possible, qui demanderait de monter en compétences sur ce genre de sujets.\nPar exemple, quand une série d\u0026rsquo;écritures sont liées entre elles fonctionnellement mais ne sont pas liées par une transaction SQL, si l\u0026rsquo;une d\u0026rsquo;elle échoue :\npour une raison métier, charge à l\u0026rsquo;application de propager des actions de compensation / rollback des écritures déjà effectuées pour une raison technique, charge à l\u0026rsquo;application de réessayer jusqu\u0026rsquo;à réussir, ou de fournir un mécanisme de two phase commit. L\u0026rsquo;autre voie serait de laisser les incohérences d\u0026rsquo;écriture se produire si elles sont peu nombreuses, et de traiter les cas par un process explicite, par exemple traitement par le support, par le pôle certif, autre ?\n"},{"id":25,"href":"/pix/adr/0026-tester-routeur-api/","title":"0026 Tester Routeur API","parent":"Adr","content":" 26. Comment tester le routeur API ? Date : 2021-04-16\nÉtat Adopté\nContexte Général Nous avons besoin de tests qui :\nempêchent les régressions fournissent un feedback rapide (s\u0026rsquo;exécutent rapidement) ne causent pas de faux positifs soient simples à comprendre, pour être facilement modifiés Le routeur de l\u0026rsquo;API (fourni par HAPI) accepte la configuration suivante pour chaque route:\nle nom de la route (path) et son verbe une validation syntaxique de la requête (effectué par JOI) une validation de sécurité de la requête (authentification) le controller à appeler si requête est validée Les tests du routeur, c’est-à-dire configuré avec les routes Pix, ont pour but de tester ces configurations en satisfaisant les critères (tous ne pouvant être satisfaits en même temps).\nSpécifique HAPI préconise\nde ne pas faire de tests depuis l\u0026rsquo;extérieur (appel HTTP) mais d\u0026rsquo;utiliser la fonction server.inject Cette pratique est déjà en place. La question à traiter ici est : quel type de serveur démarrer ?\nType de test Le routeur est soumis à deux types de test :\nintégration avec le contrôleur : vérifier que la valeur de retour du handler est renvoyée par le routeur au client acceptance : vérifier que le routeur effectue les vérifications, appelle le handler et renvoie la valeur de retour Le test d\u0026rsquo;intégration n\u0026rsquo;a pas besoin que le routeur transmette des valeurs au controlleur, car celui-ci est stubbé pour renvoyer une valeur. On peut donc se passer des vérifications syntaxiques et de sécurité.\nDans les tests d\u0026rsquo;acceptance, les tests utilisent les composants réels (controller, use-case/repository). Comme l\u0026rsquo;identification du client se fait via le token, il n\u0026rsquo;est pas possible de désactiver l\u0026rsquo;authentification, sinon le userId n\u0026rsquo;est pas disponible dans request.auth.credentials. De plus, les tests d\u0026rsquo;acceptance ont pour but premier de prévenir des régressions, ce qui suppose d\u0026rsquo;utiliser une configuration proche de la production.\nOn ne peut donc pas se passer des vérifications syntaxiques et de sécurité.\nType de serveurs Serveur de production (lourd) Appellé server.js, il est démarré en un appel par le script racine.\nAvantages :\nprotège complètement des régressions Inconvénients :\nfeedback moins rapide qu\u0026rsquo;un serveur léger (démarrage plus lent) n\u0026rsquo;attire pas l\u0026rsquo;attention du développeur sur les routes en cours de tests Serveur de test (léger) Appelé http-test-server, il ne contient uniquement instance Hapi sans routes. Aucun plugin n\u0026rsquo;est chargé. La route à tester doit lui être indiqué, auquel cas il appliquera la validation syntaxique.\nAvantages :\nfocalisation du développeur sur la route à tester feedback plus rapide qu\u0026rsquo;un serveur lourd (démarrage plus rapide) Inconvénients :\nprotège moins des régressions (ne permet pas de tester les plugins et la validation de sécurité) Solution n°1 : Utiliser un serveur de production (lourd) partout Avantages :\nprotège complètement des régressions simplifie le choix pour le développeur Inconvénients :\nfeedback moins rapide qu\u0026rsquo;un serveur léger n\u0026rsquo;attire pas l\u0026rsquo;attention du développeur sur les routes en cours de tests Solution n°2 : Utiliser un serveur de test (léger) dans les tests d\u0026rsquo;intégration Avantages pour les tests d\u0026rsquo;intégration :\nexécution plus rapide facilite l\u0026rsquo;écriture en permettant de ne pas utiliser de token Inconvénients :\nle développeur doit connaître le serveur de test et où l\u0026rsquo;utiliser Décision La solution n°2 est adoptée, car elle est déjà largement utilisée.\nConséquences Ajouter une règle de lint pour indiquer le serveur à utiliser dans les tests d\u0026rsquo;intégration.\n"},{"id":26,"href":"/pix/adr/0027-stocker-temporairement-api/","title":"0027 Stocker Temporairement API","parent":"Adr","content":" 27. Comment stocker temporairement des données dans l\u0026rsquo;API ? Date : 2021-05-28\nÉtat Adopté\nContexte Besoin fonctionnel Nous avons besoin de stocker des données PE entre le moment où l\u0026rsquo;utilisateur :\nse connecte à son compte PE; accepte les CGU Pix, ce qui mène à la création de son compte Pix. Ces données PE :\nsont issues du protocole OpenID, et ne peuvent être stockées dans le front; sont obtenues par un appel à l\u0026rsquo;API externe Pôle emploi; sont volatiles : au bout d\u0026rsquo;un certain temps, elles ne sont plus utilisables; peuvent n\u0026rsquo;être jamais lues, par exemple si l\u0026rsquo;utilisateur refuse les CGU Besoin technique Nous avons besoin de partager des données volatiles entre deux appels API.\nLes données seront :\nécrites une fois; supprimées automatiquement au bout d\u0026rsquo;un certain délai Recherche de solution Les appels à l\u0026rsquo;API externe Pôle emploi peuvent être opérés par des conteneurs API PIX différents, et les conteneurs étant par définition stateless, il n\u0026rsquo;est pas possible de stocker des données PE.\nOn ne peut pas stocker des données dans la mémoire du conteneur API PIX On ne peut pas stocker des données sur le filesystem du conteneur API PIX Il faut donc stocker ces données en dehors des conteneurs API PIX.\nLes données peuvent être stockées dans la base de données, mais leur caractère volatile et la possibilité qu\u0026rsquo;elles ne soient jamais lues, confèrent de nombreux inconvénients à cette solution.\nLes solutions restantes reposent sur le data-store redis, extérieur aux conteneurs API PIX et déjà utilisé.\nL\u0026rsquo;utilisation existante est un cache. Il ne répond pas totalement à notre demande, car un cache :\nest conçu pour être lu de nombreuses fois; ne possède pas de mécanisme d\u0026rsquo;expiration si la donnée n\u0026rsquo;est plus utilisable Par contre, le data-store lui-même offre les fonctionnalités suivantes :\nSauvegarder une donnée pendant une certaine période, indiquée par un délai d\u0026rsquo;expiration (nombre de secondes) cf. EX Deux possibilités s\u0026rsquo;offrent à nous :\ncréer un composant dédié qui invoquera ces commandes sur le data-store; modifier le cache pour qu\u0026rsquo;il ne les invoque que dans un cas particulier Solution 1 : créer un composant dédié Utiliser la class RedisClient\nImplémenter un composant avec le contrat suivant :\nsave: écrire une clef avec une durée d\u0026rsquo;expiration; get: lire une clef Avantage :\nexplicite le comportement (pas de mention du cache) Inconvénient :\ncoût de développement d\u0026rsquo;un nouveau composant Solution 2 : modifier la solution de cache existante Modifier la solution existante de cache pour fournir un délai d\u0026rsquo;expiration.\nGarder le contrat pour les clients existants.\nModifier le contrat pour un nouveau client :\nset: écrire une clef avec une durée d\u0026rsquo;expiration; get: lire une clef puis la supprimer Avantages :\nle comportement attendu est contre-intuitif (le composant se nomme cache); pas de développement d\u0026rsquo;un nouveau composant Inconvénient :\ncouplage: risque de régression, d\u0026rsquo;évolutions hors scope Décision La solution n°1 est adoptée, car elle est la plus maintenable\nConséquences Création d\u0026rsquo;un dossier temporary-storage sous le dossier infrastructure.\nAfin de gérer les changements de délai d\u0026rsquo;expiration de l\u0026rsquo;API externe sans modifier le code, celui-ci sera paramétrable dans une variable d\u0026rsquo;environnement. Celle-ci aura une valeur par défaut correspondant au délai connu à ce jour.\n"},{"id":27,"href":"/pix/adr/0028-remplacer-orm-bookshelfjs-par-query-builder-knexjs/","title":"0028 Remplacer Orm Bookshelfjs Par Query Builder Knexjs","parent":"Adr","content":" 28. Remplacer l\u0026rsquo;usage de l\u0026rsquo;ORM BookshelfJS par le query-builder KnexJS Date : 2021-06-29\nÉtat En cours\nContexte Choix initial de l\u0026rsquo;ORM BookshelfJS comme outil d\u0026rsquo;interaction avec la base de données Dans l\u0026rsquo;intention louable de produire et livrer rapidement, l\u0026rsquo;utilisation d\u0026rsquo;un ORM, BookshelfJS, a été adoptée afin de gérer les interactions dans l\u0026rsquo;API avec la base de données PostgreSQL. Les ORMs sont des bibliothèques qui permettent de communiquer avec une base de données en offrant la possibilité de mettre en évidence des objets, et des relations entre eux, qui vont venir se calquer au schéma d\u0026rsquo;une base de données. Ces avantages sont très intéressants sur le papier et réels dans les premiers temps d\u0026rsquo;un projet, mais à mesure que celui-ci grandit et que les problématiques qu\u0026rsquo;il adresse deviennent pointues, ils laissent la place à des écueils et autres inconvénients que nous rencontrons désormais :\nApporter de l\u0026rsquo;abstraction vis à vis des détails techniques d\u0026rsquo;interaction avec la BDD. La promesse des ORMs est que le code produit sera compatible quel que soit le système de base de données relationnelles (MySQL, PostgreSQL, SQLite, etc\u0026hellip;). Alléger la charge mentale du développeur en ne lui imposant plus une connaissance fine du langage SQL. Facilement déclarer et requêter sur des objets du domaine lesquels sont parfois stockés de façon complexe en BDD (multi-tables, relations étrangères, etc\u0026hellip;). Améliorer la lisibilité des interactions avec la BDD en faisant en sorte d\u0026rsquo;intéragir avec des entités métiers. Les avantages sont très intéressants sur le papier, mais en réalité cela s\u0026rsquo;avère être un peu plus compliqué.\nLes difficultés rencontrées aujourd\u0026rsquo;hui Aujourd\u0026rsquo;hui, la plateforme Pix doit gérer tous les jours un nombre important de requêtes utilisateurs, et donc doit gérer un nombre tout aussi important d\u0026rsquo;interactions avec la BDD. A la fois du point de vue des performances mais aussi du quotidien du développeur, BookshelfJS présente de plus en plus d\u0026rsquo;inconvénients, qui sont en fait connus des ORMs et qui constituent leurs limites.\nAfin de tenir leurs promesses, les ORMs sont en réalité des bibliothèques complexes avec une interface riche. Il s\u0026rsquo;avère finalement que la montée en compétence sur l\u0026rsquo;usage de l\u0026rsquo;outil (et la maintenance du code associé) n\u0026rsquo;est pas si évidente. Les ORMs, à partir du code produit en utilisant leur bibliothèque, génèrent automatiquement les requêtes SQL associées. Pour des requêtes simples sur des objets simples de type CRUD, le SQL généré est plutôt efficace. Malheureusement, dès lors que l\u0026rsquo;on souhaite réaliser des opérations un peu plus complexes, cela devient vite une lutte avec la bibliothèque. De plus, souvent, celle-ci va générer un SQL pas toujours performant. // Exemple inspiré de code existant de récupération // d\u0026#39;un assessment-result avec ses competence-marks const assessmentResultBookshelf = await BookshelfAssessmentResult .where({ id: 123 }) .fetch({ withRelated: [\u0026#39;competenceMarks\u0026#39;] }); # SQL généré SELECT \u0026#34;assessment-results\u0026#34;.* FROM \u0026#34;assessment-results\u0026#34; WHERE \u0026#34;id\u0026#34; = $1 LIMIT $2; (bindings : {123, 1}) SELECT DISTINCT \u0026#34;competence-marks\u0026#34;.* FROM \u0026#34;competence-marks\u0026#34; WHERE \u0026#34;competence-marks\u0026#34;.\u0026#34;assessmentResultId\u0026#34; IN ($1); (bindings : {123}) On constate que :\nDeux requêtes sont générées alors que cela pourrait être réalisé en une seule, et celles-ci sont exécutées à chaque fois dans une transaction BDD différente (donc une connexion BDD à renouveler). La syntaxe est destinée à fonctionner pour tellement de cas différents qu\u0026rsquo;elle est trop générique et peut ralentir la requête (ici le DISTINCT n\u0026rsquo;est pas nécessaire par exemple). La promesse d\u0026rsquo;abstraction ORM est trompeuse à plusieurs titres : d\u0026rsquo;une part, le développeur n\u0026rsquo;apprend pas le SQL (langage largement utilisé) mais apprend à la place à apprivoiser une interface ORM complexe qui n\u0026rsquo;est que très peu commune avec les autres ORMs. D\u0026rsquo;autre part, le développeur est fin de compte tenu de comprendre un peu le SQL pour débugger et optimiser. Aussi l\u0026rsquo;on doit admettre que l\u0026rsquo;usage qu\u0026rsquo;on fait de BookshelfJS dans la base de code est loin de l\u0026rsquo;usage classique que l\u0026rsquo;on ferait d\u0026rsquo;un ORM. L\u0026rsquo;idée initiale est de représenter les données de la base de données et les relations qu\u0026rsquo;elles entretiennent entre elles par des objets dans le code.\nAinsi, on pourrait les manipuler comme si nous manipulions des objets du domaine, mais aussi effectuer simplement et de façon très abstraite les opérations de persistance ou de rollback. Dans les faits, nous avons en fait nos propres objets du domaine (api/lib/domain/models VS api/lib/infrastructure/orm-models). Pire, la durée de vie des modèles BookshelfJS instanciés suite à récupération de données dans la base de données est très courte.\nExtrait légèrement modifié du fichier campaign-repository.jsG :\nconst bookshelfCampaign = await BookshelfCampaign .where({ id }) .fetch(); return bookshelfToDomainConverter.buildDomainObject(BookshelfCampaign, bookshelfCampaign); Il est très clair que l\u0026rsquo;instance BookshelfJS du modèle campagne (bookshelfCampaign) a une durée de vie très courte et est presque immédiatement délaissée au profit de sa conversion en objet de notre domaine.\nLe problème en soi n\u0026rsquo;est pas réellement d\u0026rsquo;avoir une structure de données intermédiaire entre la sortie des données de la BDD et la transformation en objet du domaine. Cette transition est incontournable. Le problème est que la structure de données intermédiaire (en l\u0026rsquo;occurrence ici les modèles BookshelfJS) est une structure complexe et lourde proposant une interface riche et inexploitée.\nPour mieux comprendre, comparons l\u0026rsquo;occupation mémoire d\u0026rsquo;une donnée récupérée via un query-builder simple (ici KnexJS) VS l\u0026rsquo;ORM BookshelfJS. Voici les chiffres pour 1500 récupérations d\u0026rsquo;un enregistrement de la table sessions (article Confluence):\nKnexJS : 47MB BookshelfJS: 127MB Décisions Vu les difficultés posées par l\u0026rsquo;utilisation de l\u0026rsquo;ORM, on trouve d\u0026rsquo;ores et déjà dans le code de multiples utilisations du query-builder KnexJS en lieu et place de BookshelfJS.\nCette ADR propose d\u0026rsquo;officialiser ce choix selon l\u0026rsquo;application suivante :\nRendre obligatoire l\u0026rsquo;usage de KnexJS pour les développements futurs Encourager au refactoring au fil de l\u0026rsquo;eau du code existant Pour aider les développeurs à faire le changement, nous proposons une Pull Request qui met en place ce changement dans le answer-repository.\nConséquences Responsabilité des développeurs et des équipes sur :\nLes nouveaux développements doivent, autant que faire se peut, utiliser KnexJS pour interroger la base de données Les équipes sont encouragées fortement à prendre du temps, à l\u0026rsquo;occasion des tickets ou de diverses tâches techniques, de procéder au changement dans le code existant Ne pas hésiter à se faire aider sur ce sujet par les personnes compétentes.\nLes conséquences positives qu\u0026rsquo;on espère constater :\nUne réduction de la charge mémoire moyenne sur les containers API Une homogénéisation du code dans l\u0026rsquo;usage globalisé de KnexJS Une meilleure maîtrise des requêtes SQL formulées à la BDD Une montée en compétence des développeurs sur le SQL Une occasion de refacto sur des repositories un peu vieux ! "},{"id":28,"href":"/pix/adr/0029-formater-template-ember/","title":"0029 Formater Template Ember","parent":"Adr","content":" 29. Formater les templates Ember Date : 2021-07-20\nÉtat En cours\nContexte Nous avons besoin de formater le code pour faciliter sa lecture. Cet ADR se propose de choisir une solution pour les templates handlebars. Il ne remet pas en cause l\u0026rsquo;outil de lint (eslint) et son plugin pour les templates handlebars. Une ambigüité peut néanmoins faire surface, car l\u0026rsquo;outil propose des règles syntaxiques, donc de formatage.\nLint et formatage Les outils d\u0026rsquo;analyse statique de code, c’est-à-dire sans exécution du code testé, sont aussi appelés outils de lint. Il existe une ambigüité avec d\u0026rsquo;autres outils, ceux de formatage, pour deux raisons.\nEn premier lieu, leur domaine d\u0026rsquo;application se chevauche. Le formatage s\u0026rsquo;occupe de la mise en page, c’est-à-dire de la présentation du code source à l\u0026rsquo;écran, pour le développeur. Son but est de rendre le code plus intelligible en effectuant des micro-décisions (ex: indentation, espace non-significatif). Un code modifié par un outil de formatage ne changera pas de comportement lors de son exécution (ex: tests automatisés). Ceci dit, un outil de lint peut disposer de fonctionnalités de formatage.\nEnsuite, leur mode de fonctionnement tend à se rapprocher. Un outil de formatage applique une série de transformations au code brut pour obtenir un code standardisé. A l\u0026rsquo;origine, il n\u0026rsquo;a aucune fonctionnalité d\u0026rsquo;assistance (ex: suggérer l\u0026rsquo;ajout d\u0026rsquo;indentation à un endroit). Au contraire, l\u0026rsquo;outil de lint ne modifie pas le code, il ne fait que l\u0026rsquo;inspecter pour produire un rapport. Or:\nles outils de lint proposent également des fonctionnalités auto-fix les outils de formatage proposent également des fonctionnalités dry-run Configuration Linter Les linter contiennent des règles qui peuvent être activées (et configurées) individuellement, par exemple une règle de formatage: présence d\u0026rsquo;une ligne vide en fin de fichier eol-last. Les linter proposent des configurations standard, aussi appelées preset, qui rassemblent des règles, par exemple celle de eslint.\nFormater Certains formaters ne proposent quasiment aucune configuration, et ne garantissent pas la continuité des règles appliquées, c’est-à-dire qu\u0026rsquo;une nouvelle release du formater peut entraîner un nouveau formatage en l\u0026rsquo;absence de modification du fichier.\nL\u0026rsquo;argumentation d\u0026rsquo;un de ces formater, Prettier est que cela permet au développeur de se concentrer sur d\u0026rsquo;autres tâches lors de l\u0026rsquo;implémentation et de la revue.\nPar exemple, il existe 20 options pour Prettier)\nUn exemple de comportement non configurable est la présence obligatoire d\u0026rsquo;une ligne vide en fin de fichier, spécifié par POSIX. La plupart du temps, le code est exécuté sur des distributions Linux non certifiées POSIX: faut-il faire figurer cette ligne vide ? Prettier répond \u0026ldquo;Oui\u0026rdquo; partout.\nPour résumer\nBy far the biggest reason for adopting Prettier is to stop all the ongoing debates over styles. Source\nTemplates Ember (hbs) Les templates utilisés par Ember (hbs - handlebars) ont pour cible le html.\nUn html peut présenter :\nune structure assez profonde (nombre de niveaux), malgré l\u0026rsquo;approche orientée composants; des éléments avec de nombreux attributs. De plus, il n\u0026rsquo;existe pas d\u0026rsquo;éditeur visuel handlebars.\nEn conséquence, un formatage approprié est important.\nApproche Pix Jusqu\u0026rsquo;ici, l\u0026rsquo;approche utilisée est:\noutil de lint; avec de nombreuses configurations spécifiques. Nous ne connaissons pas le besoin à l\u0026rsquo;origine des configurations spécifiques.\nSolution n°1: utiliser les règles syntaxiques du linter natif Le linter natif ember-template-lint propose des règles d\u0026rsquo;inspection du formatage. Elles sont embarquées dans le preset stylistic, voici une règle en exemple.\nAvantages:\nconfigurable bibliothèque déjà présente Inconvénients:\npas d\u0026rsquo;option auto-fix sur le formatage pour l\u0026rsquo;instant: la reprise d\u0026rsquo;historique (ex: indentation) doit notamment être faite manuellement Solution n°2: utiliser le formater Prettier Avantages:\ntrès peu configurable (20 options en tout) le code en cours d\u0026rsquo;écriture et la reprise d\u0026rsquo;historique sont automatiquement corrigés Inconvénients:\nabandon imposé de certaines règles, par exemple l\u0026rsquo;absence de ligne vide en fin de fichier support considéré comme expérimental Prettier peut déclenché :\nindépendamment par le linter (eslint-template-lint) via le plugin ember-template-lint-plugin-prettier Décisions Comme il n\u0026rsquo;y a pas consensus, mais qu\u0026rsquo;aucun argument n\u0026rsquo;est apporté contre Prettier, décision est prise d\u0026rsquo;essayer Prettier sur un repository de taille réduite (Pix Admin) et de faire un bilan d\u0026rsquo;ici quelques mois.\nConséquences Installer Prettier.\nL\u0026rsquo;intégrer au linter pour qu\u0026rsquo;il soit intégré à la CI (installer le plugin ember-template-lint-plugin-prettier).\nAjouter une tâche npm qui permet de formater, car tous les IDE ne prennent pas en compte la configuration de Prettier via eslint-template-lint, stockée dans le fichier .template-lintrc.js.\n\u0026quot;lint:hbs:fix\u0026quot;: \u0026quot;prettier **/*.hbs --write --parser=glimmer\u0026quot;\n"},{"id":29,"href":"/pix/adr/0030-revoir-le-choix-d-une-librairie-de-gestion-des-dates/","title":"0030 Revoir Le Choix D Une Librairie De Gestion DES Dates","parent":"Adr","content":" 30. Revoir le choix de l\u0026rsquo;utilisation de la librairie Moment.js Date : 2021-07-21\nÉtat Adopté\nContexte L\u0026rsquo;API de date ECMAScript n\u0026rsquo;est pas pratique, d\u0026rsquo;où l\u0026rsquo;utilisation de Moment qui était la solution la plus répandue en 2016.\nLes difficultés rencontrées aujourd\u0026rsquo;hui La librairie n\u0026rsquo;est plus maintenue. L\u0026rsquo;immutabilité diminue le nombre de bugs, or les objets Moment sont mutables. La taille du bundle de l\u0026rsquo;application sera plus grande qu\u0026rsquo;avec une autre librairie. La tactique du tree shaking permet de réduire cette taille en enlevant les fonctionnalités non utilisées (par exemple l\u0026rsquo;internationalisation). Mais celle-ci n\u0026rsquo;est pas disponible pour Moment.\nDe plus, Moment ne gère pas correctement l\u0026rsquo;arabe et le coréen et l\u0026rsquo;internationalisation est très verbeuse.\nD\u0026rsquo;autre part, ChartJs est utilisé pour Pix Orga pour tout ce qui a trait à la Data Visualisation (notamment pour les graphiques de type time). Moment pose des problèmes d\u0026rsquo;intégration avec ChartJs.\nVoir les détails\nSolution n°1 : Garder Moment.js Défaut :\nPoids élevé dans le bundle final (80kb). Avantages :\nLibrairie très utilisée qui présente désormais moins de bugs. Librairie populaire, gage de facilité d\u0026rsquo;intégration pour de nouveaux arrivants. Déjà utilisée chez Pix, pas de migration nécessaire. Solution n°2 : Migrer vers Day.js Défaut :\nNécessité de migrer vers cette solution. Avantages :\nPoids réduit dans le bundle final (6kb). Day.js utilise la même API que Moment, facilitant ainsi l\u0026rsquo;appropriation par les équipes. Solution n°3 : Migrer vers date-fns Avantage :\nInterface fonctionnelle FP, familière aux développeurs Pix. Défauts :\nNécessité de migrer vers cette solution. Même avec le tree-shaking, le bundle final est plus volumineux que Day.js (13kb). Format de date différent des autres librairies. Solution n°4 : Migrer vers Luxon Défauts :\nNécessité de migrer vers cette solution. Pas de tree-shaking, le bundle final est plus volumineux que Day.js (20kb). Avantages :\nCette librairie est maintenue. Solution n°5 : Utiliser les fonctions natives Intl La fonctionnalité ECMAScript est décrite ici. Elle est disponible partout, même sur IE11. Elle permet de gérer les dates, y compris les dates internationalisées.\nAvantages :\nGage de facilité d\u0026rsquo;intégration pour de nouveaux arrivants. Défauts :\nNécessité de migrer vers cette solution. Assez verbeux. Temporal La fonctionnalité ECMAScript est décrite ici. Elle permet de gérer les dates, y compris les dates internationalisées.\nAvantages :\nGage de facilité d\u0026rsquo;intégration pour de nouveaux arrivants. Défauts :\nNécessité de migrer vers cette solution. Toujours en catégorie expérimentale (Stage 3 TC39), donc non stable. Décisions Nous choisissons la solution Day.js parce que :\nLe gain de poids est le plus important. Son utilisation est similaire à celle de Moment pour les fonctionnalités de base. Conséquences Pour gagner immédiatement de la taille sur le bundle, remplacer intégralement Moment.\nSuivre par exemple ce guide de migration .\n"},{"id":30,"href":"/pix/adr/0031-uniformiser-la-validation-des-chaines-de-caracteres/","title":"0031 Uniformiser La Validation DES Chaines De Caracteres","parent":"Adr","content":" 31. Supprimer une propriété de type texte Date : 2022-02-16\nEtat Accepté\nContexte Lors de la réalisation de cette pull request. Nous avons besoin de supprimer une propriété de type texte sur un objet déjà présent en base de données, par exemple la description d\u0026rsquo;un badge. Il existe actuellement plusieurs manières de le faire côté front :\nenvoyer une chaîne vide envoyer null La deuxième possibilité se traduit généralement par une ternaire qui vérifie si la chaîne est vide avant de l\u0026rsquo;envoyer à l\u0026rsquo;API.\nCôté API, il existe aussi plusieurs manières de valider les chaînes de caractères reçues :\nJoi.string().required().allow('') - La propriété doit être présente mais on accepte les chaînes vides Joi.string().required().allow(null) - La propriété doit être présente mais on accepte null Joi.string().empty('').allow(null).optional() - La propriété n\u0026rsquo;est pas obligatoire, on accepte null et une chaîne vide est considéré comme undefined Joi.string().allow(null).optional() - La propriété n\u0026rsquo;est pas obligatoire et on accepte null On peut déduire des validations précédentes un certains nombre de cas:\nLa propriété n\u0026rsquo;est pas présente dans le payload La propriété vaut chaîne vide La propriété vaut null La propriété est une chaîne de caractère non vide Chacun de ces cas laisse transparaître une intention plus ou moins claire :\nOn veut vider le champ ou ne rien faire ? On veut vider le champ ou on veut stocker une chaîne vide ? On veut vider le champ On veut mettre à jour le champ On constate que dans les deux premiers cas il peut y avoir un doute.\nOn souhaiterait donc :\nFaciliter les choix des développeurs lorsqu\u0026rsquo;il doivent écrire la validation côté API Définir une manière claire de supprimer une propriété de type texte Les difficultés rencontrées aujourd\u0026rsquo;hui Il est important aussi de préciser que par le passé, suite à des mises à jours de données manuelles, il y a des chaînes vides au lieu de NULL (SQL), ce qui avait une incidence sur la manière dont la donnée était interpretée par l\u0026rsquo;API.\nSolution n°1 : Utiliser la valeur null La valeur null est utilisée pour signifier qu\u0026rsquo;on veut supprimer une propriété de type texte.\nOn n\u0026rsquo;autorise que deux intentions claires côté validation :\nsupprimer la propriété avec la valeur null mettre à jour la propriété avec une chaîne de caractères différente de \u0026quot;\u0026quot; Avantages Deux intentions clairement définies, il n\u0026rsquo;y a pas de questions à se poser Le code de l\u0026rsquo;API a majoritairement été pensé pour gérer la valeur null dû à notre utilisation de Postgres La validation à l\u0026rsquo;heure actuelle tend vers une utilisation de la value null en majorité Inconvénients API est plus restrictive Néccessite une ternaire côté front valeur.trim() === \u0026quot;\u0026quot; ? null : valeur (cet inconvénient peut être mitigé avec l\u0026rsquo;usage d\u0026rsquo;un transform Ember) Solution n°2 : Utiliser la valeur \u0026quot;\u0026quot; La valeur \u0026quot;\u0026quot; est utilisée pour signifier qu\u0026rsquo;on veut supprimer une propriété de type texte.\nOn n\u0026rsquo;autorise que deux intentions claires côté validation :\nsupprimer la propriété avec la valeur \u0026quot;\u0026quot; mettre à jour la propriété avec une chaîne de caractères différente de \u0026quot;\u0026quot; Avantages Deux intentions clairement définies, il n\u0026rsquo;y a pas de questions à se poser Pas de gestion spécifique sur les chaînes côté front (pas de ternaire avant l\u0026rsquo;envoi à l\u0026rsquo;API) Inconvénients On faut changer le code backend pour gérer les chaînes vides correctement côté API Dans la majorité des usages en termes de validation on utilise null à l\u0026rsquo;heure actuelle API est plus restrictive Si on décide de stocker en base de données la valeur \u0026quot;\u0026quot; :\nOn se prive des opérateurs SQL lié à la valeur NULL (ex: IS NULL/IS NOT NULL) Solution n°3 : Utiliser des solutions spécifiques On va définir la validation des propriétés de type texte en fonction des usages pour avoir la solution la plus adaptée possible.\nOn n\u0026rsquo;autorise des valeurs multiples côté validation qui peuvent réfléter un ensemble d\u0026rsquo;intentions diverses (\u0026quot;\u0026quot;, \u0026quot; \u0026quot;, une chaîne différente de \u0026quot;\u0026quot; ou \u0026quot; \u0026quot;, undefined ou encore null).\nAvantages On a une solution adaptée à notre cas particulier qui justifie l\u0026rsquo;usage d\u0026rsquo;une chaîne vide plutôt que null API permissive Inconvénients Les développeurs doivent systématiquement se poser la question (charge cognitive en plus) Les intentions ne sont pas clairement définies entre (\u0026quot;\u0026quot;, null ou undefined). Elles peuvent varier d\u0026rsquo;un usage à un autre. Pas d\u0026rsquo;uniformisation du design de l\u0026rsquo;API Décisions On choisit donc la solution n°1 qui semble répondre le mieux à la problématique.\nConséquences On utilise la validation Joi (dans le routeur ou le domaine) suivante pour les propriétés de type texte :\nJoi.string().allow(null).required() On ajoute le transform suivante dans les applications Ember pour éviter l\u0026rsquo;utilisation de ternaire :\nimport Transform from \u0026#39;@ember-data/serializer/transform\u0026#39;; export default class StringTransform extends Transform { serialize(string) { if (string.trim() === \u0026#39;\u0026#39;) { return null; } return string; } deserialize(string) { return string; } } "},{"id":31,"href":"/pix/adr/0032-utiliser-pgboss-pour-les-taches-asynchrone/","title":"0032 Utiliser Pgboss Pour Les Taches Asynchrone","parent":"Adr","content":" 1. Gestion des tâches asynchrones avec PgBoss Date : 2022-02-24\nÉtat En cours\nContexte L\u0026rsquo;utilisation des évènements dans l\u0026rsquo;application a mis en évidence des problématiques de cohérences des données que nous ne gérons pas pour le moment. Quand un évènement est lancé après l\u0026rsquo;exécution d\u0026rsquo;un use case et que l\u0026rsquo;application plante, les traitements liés à la gestion de l\u0026rsquo;évènement ne sont pas forcément exécutés. Par exemple après le partage des résultats d\u0026rsquo;une participation à une campagne nous utilisons un évènement pour déclencher le calcul du snapshot des résultats. En cas de problème, la participation est partagée, mais on peut ne pas avoir de snapshot.\nC\u0026rsquo;est une situation qui s\u0026rsquo;est produite lorsque Scalingo a fait de la maintenance sur les bases de données.\nSolution : PgBoss PgBoss est une job queue qui est persisté dans une base PostgreSQL.\nLa solution s\u0026rsquo;oriente vers PgBoss parce que la queue est dans un base PG, tout comme le reste de nos données. On peut envisager d\u0026rsquo;ajouter un job en BDD et de faire les traitements d\u0026rsquo;un use case dans une même transaction. Ce qui permet de ne pas perdre le traitement d\u0026rsquo;un évènement en cas d\u0026rsquo;erreur.\n1. Les migrations PgBoss Les migrations PgBoss sont jouées quand on appelle la fonction pgBoss.start().\nCes migrations peuvent prendre du temps s\u0026rsquo;il existe beaucoup de jobs dans la BDD. Pour pouvoir jouer ces migrations sans introduire ce problème il faut ajouter au script db:migrate l\u0026rsquo;appel à la fonction start de PgBoss.\n// api/package.json \u0026#34;db:migrate\u0026#34;: \u0026#34;knex --knexfile db/knexfile.js migrate:latest \u0026amp;\u0026amp; node scripts/database/run-pg-boss-migration.js\u0026#34;, require(\u0026#39;dotenv\u0026#39;).config(); const PgBoss = require(\u0026#39;pg-boss\u0026#39;); async function main() { console.log(process.env); const databaseUrl = process.env.NODE_ENV === \u0026#39;test\u0026#39; ? process.env.TEST_DATABASE_URL : process.env.DATABASE_URL; const boss = new PgBoss(databaseUrl); await boss.start(); await boss.stop(); } Le but c\u0026rsquo;est de ne pas avoir à faire le pgBoss.start à chaque fois qu\u0026rsquo;on lance PgBoss et de prendre le risque que le start prenne du temps à cause de migrations. Si jamais un start est fait dans un conteneur web on peut bloquer un worker le temps de faire les migrations PgBoss.\n2. Ajouter un job Dans le conteneur web le contrôleur utilisera les évènements pour créer des jobs. On doit créer une classe / service qui sera instancié (en prenant la transaction knex en paramètre) dans l\u0026rsquo; EventDispatcher. Ensuite, l\u0026rsquo;EventDispatcher passera cette classe / service au handler qui l\u0026rsquo;utilisera pour ajouter un job.\nLa classe / service fera une requête en BDD pour ajouter une ligne dans la table job du schéma de PgBoss en spécifiant le nom (name), paramètres (data) et les informations pour configurer le job.\nJob table The following command is the definition of the primary job table. For manual job creation, the only required column is name. All other columns are nullable or have sensible defaults.\nCREATE TABLE ${schema}.job ( id uuid primary key not null default gen_random_uuid(), name text not null, priority integer not null default(0), data jsonb, state ${schema}.job_state not null default(\u0026#39;${states.created}\u0026#39;), retryLimit integer not null default(0), retryCount integer not null default(0), retryDelay integer not null default(0), retryBackoff boolean not null default false, startAfter timestamp with time zone not null default now(), startedOn timestamp with time zone, singletonKey text, singletonOn timestamp without time zone, expireIn interval not null default interval \u0026#39;15 minutes\u0026#39;, createdOn timestamp with time zone not null default now(), completedOn timestamp with time zone, keepUntil timestamp with time zone NOT NULL default now() + interval \u0026#39;14 days\u0026#39;, on_complete boolean not null default true, output jsonb ) Pour pouvoir faire ça il faut repasser à l\u0026rsquo;EventDispatcher la transaction à chaque traitement d\u0026rsquo;évènement.\nEn faisant ça il faut ABSOLUMENT que toutes les requêtes faites dans le handler passe par la transaction, sinon on prend le risque d\u0026rsquo;avoir des deadlocks. C\u0026rsquo;est à cause de ces problèmes qu\u0026rsquo;on a décidé de ne plus utiliser les transactions dans les handler d\u0026rsquo;évènement. Quand la gestion d\u0026rsquo;évènement a été mise en place on n\u0026rsquo;a pas assez communiqué et formé les gens sur ce point.\nEn fonction des jobs on peut vouloir les lancer plusieurs fois ou pas. Il n\u0026rsquo;y a pas de garantie qu\u0026rsquo;un job n\u0026rsquo;est pas déjà été exécuté. Par exemple le job marche, mais le conteneur plante avant que PgBoss mette à jour le job en BDD. Le job aura été exécuté, mais il n\u0026rsquo;est pas marqué comme terminé. Dans cette situation PgBoss finira par relancer le job. Pour chaque job il faut savoir si on peut / doit le rejouer en cas d\u0026rsquo;échec. Par exemple un envoi de mail ne doit pas forcément être relancé, par opposition il y a peu d\u0026rsquo;impact si on calcule plusieurs fois les résultats d\u0026rsquo;un participant à une campagne.\nEn fonction du contexte il faut déterminer si jouer le job plusieurs fois est acceptable.\n💡 Une classe/service par job peut permettre de configurer la file facilement. (Nombre de tentatives par exemple).\n💡 Il faudrait des logs pour monitorer l\u0026rsquo;ajout des jobs dans Datadog. (Avec de l\u0026rsquo;héritage c\u0026rsquo;est faisable facilement).\nExemple non contractuel class Job { constructor(config, queryBuilder, logger) { this.name = config.name; this.retryLimit = config.retryLimit || 0; this.retryDelay = config.retryDelay || 30; this.queryBuilder = queryBuilder; this.logger = logger; } async schedule(data) { await this.queryBuilder.raw( \u0026#39;INSERT INTO pgboss.job (name, data, retryLimit, retryDelay) VALUES (:name, :data, :retryLimit, :retryDelay)\u0026#39;, { name: this.name, retryLimit: this.retryLimit, retryDelay: this.retryDelay, data, } ); this.logger.info(`Job ${this.name} scheduled`); } } class JobRetryEnabled extends Job { constructor(queryBuilder, logger) { super({ name: \u0026#39;RetryEnabled\u0026#39;, retryLimit: 3 }, queryBuilder, logger); } } class JobRetryDisabled extends Job { constructor(queryBuilder, logger) { super({ name: \u0026#39;RetryDisable\u0026#39; }, queryBuilder, logger); } } 3.Lancer un job Il y aura un conteneur dédié pour jouer les jobs (dans la même idée que celui avec les CRON).\nJobQueue Pour ne pas dépendre trop directement de PgBoss il faut wrapper PgBoss dans une classe ou un service.\nExemple non contractuel const PgBoss = require(\u0026#39;pg-boss\u0026#39;); class JobQueue { constructor() { this.pgBoss = new PgBoss(process.env.DATABASE_URL); } async performJob(name, handler) { await this.pgBoss.start(); this.pgBoss.work(name, (job) =\u0026gt; { handler(job.data); }); } async stop() { await this.pgBoss.stop({ graceful: false, timeout: 1000 }); } } On peut ajouté des tests automatisés sur le wrapper. C\u0026rsquo;est des tests qui ont un interêt en cas de montée de version de PgBoss ou de changement le lib. (Ce n\u0026rsquo;est pas forcément utile de lancer ces tests dans la CI).\nExemple non contractuel beforeEach(async function () { await knex(\u0026#39;job\u0026#39;) .withSchema(\u0026#39;pgboss\u0026#39;) .insert({ name: \u0026#39;job\u0026#39;, data: { jobParam: 1 } }); }); it(\u0026#39;executes job when a job is added to the queue\u0026#39;, function (done) { const handler = (params) =\u0026gt; { try { expect(params).to.deep.equal({ jobParam: 1 }); done(); } catch (err) { done(err); } }; const jobQueue = new JobQueue(knex); jobQueue.performJob(\u0026#39;job\u0026#39;, handler); }); JobHandler Pour les mêmes raisons (testabilité, indépendance, \u0026hellip;) il est nécéssaire de wrapper les jobs dans des classes / services.\nExemple non contractuel Version sans transaction\nconst DomainTransaction = require(\u0026#39;../DomainTransaction\u0026#39;); class JobHandler { constructor(name, jobQueue, dependencies = {}) { this.name = name; this.dependencies = dependencies; this.jobQueue = jobQueue; } async perform() { const handler = (params) =\u0026gt; this._handle({ ...params, ...this.dependencies }); await this.jobQueue.performJob(this.name, handler); } async _handle() { throw new Error(\u0026#39;NOT IMPLEMENTED\u0026#39;); } async stop() { await this.jobQueue.stop({ graceful: false, timeout: 1000 }); } } class JobPocHandler extends JobHandler { constructor(jobQueue, logger) { super(\u0026#39;job\u0026#39;, jobQueue); this.logger = logger; } async _handle({ date }) { this.logger.info(`Job Trx ${date}: STARTED`); setTimeout(() =\u0026gt; this.logger.info(`Job ${date}: Sleeping`), 5000); await sleep(10000); this.logger.info(`Job ${date}: FINISHED`); } } Version avec transaction\nclass JobTrxHandler extends JobHandler { async perform() { const handler = async (params) =\u0026gt; { await DomainTransaction.execute(async (domainTransaction) =\u0026gt; { await this._handle({ ...params, domainTransaction, ...this.dependencies }); }); }; await this.jobQueue.performJob(this.name, handler); } } class JobPocTrxHandler extends JobTrxHandler { constructor(jobQueue, logger) { super(\u0026#39;job\u0026#39;, jobQueue); this.logger = logger; } async _handle({ domainTransaction }) { await domainTransaction .knexTransaction(\u0026#39;organizations\u0026#39;) .update({ name: `Orga-PgBoss` }) .where({ id: 1 }); } } Les tests\nExemple non contractuel it(\u0026#39;update organization name\u0026#39;, async function () { databaseBuilder.factory.buildOrganization({ id: 1, name: \u0026#39;Orga\u0026#39; }); await databaseBuilder.commit(); const jobQueue = { performJob: async function (name, handler) { await handler(); }, }; const jobHandler = new JobPocTrxHandler(jobQueue); await jobHandler.perform(); const organization = await knex(\u0026#39;organizations\u0026#39;).where({ id: 1 }).first(); expect(organization.name).equal(\u0026#39;Orga-PgBoss\u0026#39;); }); Je n\u0026rsquo;ai pas réussi à utiliser une transaction pour l\u0026rsquo;exécution du job et la mise à jour du job par PgBoss. Il y a plusieurs requêtes faites par PgBoss :\nRécupération de job. Modification du statut job. Archivage des jobs. La lib permet de créer une transaction à chaque fois, mais c\u0026rsquo;est complexe d\u0026rsquo;utiliser une même transaction pour le job et la mise à jour du statut du job.\nConclusion Ça fonctionne et ce n\u0026rsquo;est pas trop dur à mettre en place. Il y a quand même quelques points d\u0026rsquo;attention.\nAvantage(s):\nPermet d\u0026rsquo;avoir une cohérence entre les traitements d\u0026rsquo;un use case et l\u0026rsquo;ajout d\u0026rsquo;un job en BDD.\nPermet d\u0026rsquo;avoir une politique de retry gratuitement.\nPermet de gérer finement le nombre de consommateurs d\u0026rsquo;une file.\nInconvénient(s):\nUtilisation de la même transaction dans le use case et dans le handler d\u0026rsquo;évènement. (Pas un vrai problème, mais on a déjà fait des bêtises)\nPas de garantie qu\u0026rsquo;un job qui a échoué n\u0026rsquo;a pas été exécuté. (Il faut gérer ça avec de la configuration de file)\nDécision Adoption de PgBoss pour la gestion des job asynchrones. PgBoss permet de rajouter un job en bdd dans la même transaction que celle d\u0026rsquo;un use case. Ce qui résout notre problématique de départ.\nConséquences On utilise PgBoss et on commence une PR avec PgBoss pour le calcul des résultats d\u0026rsquo;une participation.\n"},{"id":32,"href":"/pix/adr/0033-tester-en-utilisant-redis/","title":"0033 Tester en Utilisant Redis","parent":"Adr","content":" 33. Tester en utilisant Redis Date : 2022-03-16\nÉtat Adopté\nContexte Notre architecture de cache repose essentiellement sur Redis. Afin d\u0026rsquo;assurer la connexion à ce dernier, nous utilisons la librairie node-redis qui est enveloppée dans une classe dédiée : RedisClient. Actuellement, cette classe est testée uniquement en local.\nDifficulté rencontrée La version 4 de cette librairie introduit des breaking changes qui auront comme conséquence de complexifier la classe RedisClient.\nAfin d\u0026rsquo;assurer le bon fonctionnement de cette partie du code, nous souhaitons mettre en place plus de tests automatisés.\nAu départ, ces derniers n\u0026rsquo;avaient pas été mis en place pour éviter d\u0026rsquo;avoir un stockage Redis qui tourne en local. Cependant, il est devenu obligatoire au fil du temps. L\u0026rsquo;ajout de ces tests n\u0026rsquo;impactera donc pas l\u0026rsquo;expérience des développeurs.\nLa classe évolue très peu, nous pouvons donc questionner la pertinence du lancement de ces tests à chaque fois dans la CI.\nSolution n°1 : Ne pas faire évoluer l\u0026rsquo;existant : tester avec un stockage Redis uniquement en local lorsqu\u0026rsquo;on le souhaite Avantages Gain de temps lors du lancement des tests Gain de temps sur la CI Évite de lancer un stockage Redis dans la CI Inconvénients Les tests peuvent être oubliés Pas de tests de bout en bout avec l\u0026rsquo;implémentation de production Solution n°2 : Tester avec un stockage Redis en local et dans la CI. Avantages Pas de risque d\u0026rsquo;oubli La CI lance les mêmes tests qu\u0026rsquo;en local Les tests de bout en bout peuvent utiliser l\u0026rsquo;implémentation de production Inconvénients Les tests peuvent être un peu plus longs Décision La solution n°2 est adoptée, étant la solution apportant le plus de bénéfices.\nConséquences Des tests sur la classe RedisClient ont été ajoutés.\n"},{"id":33,"href":"/pix/adr/0033-utiliser-noms-contraintes-metiers-lisibilite/","title":"0033 Utiliser Noms Contraintes Metiers Lisibilite","parent":"Adr","content":" 34. Nom des contraintes sur la base PG Date : 2022-06-01\nÉtat En cours\nContexte Nous sommes amenés à générer des contraintes d\u0026rsquo;unicité entre plusieurs colonnes pour différents contextes métier. PG limite le nom des contraintes à 63 caractères.\nLa majorité des contraintes sont générées par knex (90% des cas). Actuellement lorsque nous créons une contrainte spécifique, nous les appelons par le nom des colonnes qui la compose. Sauf que dans certains cas nous atteignons la limite des 63 caractères. A savoir que peu importe le nom que nous donnons à notre contrainte elle sera tronqué si elle dépasse cette limite.\nNous avons eu deux incidents côté Prescription / Certification. Une contrainte utilisant des colonnes quasiment similaire mais une fois tronqué, les noms de contraintes étaient identique.\nExemple non contractuel Deux contraintes d\u0026rsquo;unicité définies avec ces colonnes : 'campaign_participations_campaignId_organizationLearnerId_isImproved_deletedAt_deletedBy_unique' 'campaign_participations_campaignId_organizationLearnerId_isImproved_participantExternalId_unique'\nLes noms qu\u0026rsquo;elles auront en base pour respecter la limite des 63 caractères sera identique, la seconde migration serait en échec : 'campaign_participations_campaignId_organizationLearnerId_isI'\nSolution 1 : Nommer les contraintes d\u0026rsquo;une manière métier et non technique Au lieu de nommer les contraintes par le nom des colonnes qui la compose, nous suggérons de les nommer par l\u0026rsquo;intention métier qu\u0026rsquo;elle assure.\nExemple non contractuel `CREATE UNIQUE INDEX \u0026lt;name\u0026gt; ON \u0026#34;campaign-participations\u0026#34; (\u0026#34;campaignId\u0026#34;, \u0026#34;organizationLearnerId\u0026#34; ) WHERE \u0026#34;isImproved\u0026#34; IS FALSE AND \u0026#34;deletedAt\u0026#34; IS NULL AND \u0026#34;deletedBy\u0026#34; IS NULL;` Une contrainte sur ces colonnes-là s\u0026rsquo;écrirait\nAvec la convention knex (94 caractères) 'campaign_participations_campaignId_organizationLearnerId_isImproved_deletedAt_deletedBy_unique'\nEn utilisant le contexte métier (35 caractères) 'one_active_participation_by_learner'\nconst OLD_UNIQUE_ORGANIZATION_ID_NATIONAL_APPRENTICE_ID_CONSTRAINT_NAME = \u0026#39;schooling_registrations_organizationid_nationalapprenticeid_uni\u0026#39;; const NEW_UNIQUE_ORGANIZATION_ID_NATIONAL_APPRENTICE_ID_CONSTRAINT_NAME = \u0026#39;organization_learners_organizationid_nationalapprenticeid_unique\u0026#39;; Avantage(s):\nPermet d\u0026rsquo;avoir une lecture simple de ce que la contrainte fait. Si des évolutions métiers font que la contrainte doit contenir une nouvelle colonne, pas besoin de renommer la contrainte pour contenir la nouvelle colonne. On limite la possibilité de dépassement des 63 caractères. Plus lisible dans le cas d\u0026rsquo;erreur en production. Réduction des risques de nommer des contraintes identiques. Ne pas devoir renommer des contraintes parce que la colonne/table a changé de nom. Inconvénient(s):\nGymnastique pas forcément innée pour les développeurs Nouvelle habitude à prendre Pas de renommage des anciennes contraintes Solution 2 : Recompiler PG afin d\u0026rsquo;augmenter le max size des nom de contraintes La longueur maximale du nom de contrainte est définie dans la constante NAMEDATALEN d\u0026rsquo;un fichier header C, donc sa valeur peut être modifiée, à condition de recompiler le code source.\nhttps://www.postgresql.org/docs/current/sql-syntax-lexical.html#SQL-SYNTAX-IDENTIFIERS\nRecompiler PG en augmentant la constante max size permettrait de gérer des nom de contraintes plus longs.\nAvantage(s):\nlaisser knex gérer le nommage des contraintes problème de longueur \u0026ldquo;résolu\u0026rdquo; Inconvénient(s):\nhébergement PaaS (nous n\u0026rsquo;avons pas la main sur cette variable d\u0026rsquo;environnement) recompiler PG Solution 3 : Générer les clés par hash Générer le nom de la contrainte avec un hash\ninconvénient(s):\nhash non symétrique, donc prend du temps pour identifier la contrainte en cas de problème (se connecter à la BDD) Conclusion La solution 2 est écartée car PGSql est hébergé par un tiers, nous ne pouvons donc effectuer l\u0026rsquo;action requise pour augmenter le max size des contraintes\nLa solution 3 est écartée pour une question de lisibilité/identification de la source du problème\nLa solution 1 semble la plus adaptée à notre contexte.\nDécision Utiliser la solution n°1, en nommant les contraintes\nmanuellement en explicitant l\u0026rsquo;intention métier On ne modifie pas le nom des contraintes déjà présentes.\nConséquences Nommer manuellement les contraintes (utiliser knex.raw)\n"},{"id":34,"href":"/pix/adr/0034-utiliser-noms-contraintes-metiers-lisibilite/","title":"0034 Utiliser Noms Contraintes Metiers Lisibilite","parent":"Adr","content":" 34. Nom des contraintes sur la base PG Date : 2022-06-01\nÉtat En cours\nContexte Nous sommes amenés à générer des contraintes d\u0026rsquo;unicité entre plusieurs colonnes pour différents contextes métier. PG limite le nom des contraintes à 63 caractères.\nLa majorité des contraintes sont générées par knex (90% des cas). Actuellement lorsque nous créons une contrainte spécifique, nous les appelons par le nom des colonnes qui la compose. Sauf que dans certains cas nous atteignons la limite des 63 caractères. A savoir que peu importe le nom que nous donnons à notre contrainte elle sera tronqué si elle dépasse cette limite.\nNous avons eu deux incidents côté Prescription / Certification. Une contrainte utilisant des colonnes quasiment similaire mais une fois tronqué, les noms de contraintes étaient identique.\nExemple non contractuel Deux contraintes d\u0026rsquo;unicité définies avec ces colonnes : 'campaign_participations_campaignId_organizationLearnerId_isImproved_deletedAt_deletedBy_unique' 'campaign_participations_campaignId_organizationLearnerId_isImproved_participantExternalId_unique'\nLes noms qu\u0026rsquo;elles auront en base pour respecter la limite des 63 caractères sera identique, la seconde migration serait en échec : 'campaign_participations_campaignId_organizationLearnerId_isI'\nSolution 1 : Nommer les contraintes d\u0026rsquo;une manière métier et non technique Au lieu de nommer les contraintes par le nom des colonnes qui la compose, nous suggérons de les nommer par l\u0026rsquo;intention métier qu\u0026rsquo;elle assure.\nExemple non contractuel `CREATE UNIQUE INDEX \u0026lt;name\u0026gt; ON \u0026#34;campaign-participations\u0026#34; (\u0026#34;campaignId\u0026#34;, \u0026#34;organizationLearnerId\u0026#34; ) WHERE \u0026#34;isImproved\u0026#34; IS FALSE AND \u0026#34;deletedAt\u0026#34; IS NULL AND \u0026#34;deletedBy\u0026#34; IS NULL;` Une contrainte sur ces colonnes-là s\u0026rsquo;écrirait\nAvec la convention knex (94 caractères) 'campaign_participations_campaignId_organizationLearnerId_isImproved_deletedAt_deletedBy_unique'\nEn utilisant le contexte métier (35 caractères) 'one_active_participation_by_learner'\nconst OLD_UNIQUE_ORGANIZATION_ID_NATIONAL_APPRENTICE_ID_CONSTRAINT_NAME = \u0026#39;schooling_registrations_organizationid_nationalapprenticeid_uni\u0026#39;; const NEW_UNIQUE_ORGANIZATION_ID_NATIONAL_APPRENTICE_ID_CONSTRAINT_NAME = \u0026#39;organization_learners_organizationid_nationalapprenticeid_unique\u0026#39;; Avantage(s):\nPermet d\u0026rsquo;avoir une lecture simple de ce que la contrainte fait. Si des évolutions métiers font que la contrainte doit contenir une nouvelle colonne, pas besoin de renommer la contrainte pour contenir la nouvelle colonne. On limite la possibilité de dépassement des 63 caractères. Plus lisible dans le cas d\u0026rsquo;erreur en production. Réduction des risques de nommer des contraintes identiques. Ne pas devoir renommer des contraintes parce que la colonne/table a changé de nom. Inconvénient(s):\nGymnastique pas forcément innée pour les développeurs Nouvelle habitude à prendre Pas de renommage des anciennes contraintes Solution 2 : Recompiler PG afin d\u0026rsquo;augmenter le max size des nom de contraintes La longueur maximale du nom de contrainte est définie dans la constante NAMEDATALEN d\u0026rsquo;un fichier header C, donc sa valeur peut être modifiée, à condition de recompiler le code source.\nhttps://www.postgresql.org/docs/current/sql-syntax-lexical.html#SQL-SYNTAX-IDENTIFIERS\nRecompiler PG en augmentant la constante max size permettrait de gérer des nom de contraintes plus longs.\nAvantage(s):\nlaisser knex gérer le nommage des contraintes problème de longueur \u0026ldquo;résolu\u0026rdquo; Inconvénient(s):\nhébergement PaaS (nous n\u0026rsquo;avons pas la main sur cette variable d\u0026rsquo;environnement) recompiler PG Solution 3 : Générer les clés par hash Générer le nom de la contrainte avec un hash\ninconvénient(s):\nhash non symétrique, donc prend du temps pour identifier la contrainte en cas de problème (se connecter à la BDD) Conclusion La solution 2 est écartée car PGSql est hébergé par un tiers, nous ne pouvons donc effectuer l\u0026rsquo;action requise pour augmenter le max size des contraintes\nLa solution 3 est écartée pour une question de lisibilité/identification de la source du problème\nLa solution 1 semble la plus adaptée à notre contexte.\nDécision Utiliser la solution n°1, en nommant les contraintes\nmanuellement en explicitant l\u0026rsquo;intention métier On ne modifie pas le nom des contraintes déjà présentes.\nConséquences Nommer manuellement les contraintes (utiliser knex.raw)\n"},{"id":35,"href":"/pix/adr/0035-image-base-docker/","title":"0035 Image Base Docker","parent":"Adr","content":" 35. Image de base docker Date : 2022-08-24\nÉtat Accepté\nContexte Sur ce projet, nous avons besoin de:\ntester le code applicatif en local et sur la CI en présence d\u0026rsquo;une base de données et d\u0026rsquo;un cache applicatif; en restant proche de l\u0026rsquo;environnement de production. Nous avons donc choisi d\u0026rsquo;utiliser la technique de conteneurs léger Docker.\nDeux choix sont possibles quand aux images de base:\néditeur de l\u0026rsquo;application; PaaS. Solution n°1 : Image de base natives Description Utiliser les images de l\u0026rsquo;éditeur, par exemple PostgreSQL.\nAvantage(s):\npoids restreint (version alpine) disponible en cache dans la CI Inconvénient(s):\nversion différente de celle exécuté par le PaaS en production Solution n°2 : Image du PaaS Description\nUtiliser les images du PaaS, par exemple Scalingo.\nAvantage(s):\nversion identique à celle exécutée en production Inconvénient(s):\ndépendance au PaaS, entrainant des spécificités image plus lourde (pas de version alpine, fonctionnalités non utilisées) pas disponible en cache dans la CI Décision Nous avons choisi la solution n°1, à savoir l\u0026rsquo;image de base native, car l\u0026rsquo;absence de dépendance aux fonctionnalités spécifiques d\u0026rsquo;un PaaS est importante.\nConséquences Garder l\u0026rsquo;image native déjà utilisée:\nlocal CI "},{"id":36,"href":"/pix/Accessibilite/","title":"Accessibilité","parent":"Pix documentation technique","content":" Vérifier l\u0026rsquo;accessibilité d\u0026rsquo;un site Plusieurs solutions (complémentaires) :\nAller sur https://validator.w3.org/ (y coller l\u0026rsquo;url du site à tester).\nInstaller l\u0026rsquo;extension de navigateur \u0026ldquo;Wave\u0026rdquo;\nCliquer sur l\u0026rsquo;icône de l\u0026rsquo;extension pour vérifier s\u0026rsquo;il y a des erreurs en naviguant sur le site. Installer l\u0026rsquo;extension de navigateur \u0026ldquo;Web Developper\u0026rdquo; (de préférence avec Firefox)\nAller dans Informations \u0026gt; View Document Outline pour vérifier la hiérarchie des titres : Cela devrait correspondre à l\u0026rsquo;ordre d\u0026rsquo;importance des informations de la page Les numéros de balises doivent se suivre : \u0026lt;h1\u0026gt;\u0026lt;h2\u0026gt; ✅ \u0026lt;h1\u0026gt;\u0026lt;h3\u0026gt; 🚨 Zoomer beaucoup (ctrl +) et vérifier si les éléments ne se superposent pas. Le zoom doit être un zoom du texte, disponible sous Firefox (via le menu affichage \u0026gt; zoom \u0026gt; zoom de texte seulement).\nSi certains éléments textes débordent (textes qui se superposent, texte qui sort d\u0026rsquo;un bouton), il faudra surement éviter les hauteurs fixes ; Pour ce qui concerne le texte, les pixels sont à bannir ! Préférez les unités relatives (rem, \u0026hellip;). Attention, cela ne fonctionne pas toujours de mettre des unités relatives pour les marges, la hauteur, \u0026hellip; Enlever les éléments graphiques et vérifier si on garde toujours l\u0026rsquo;information (par exemple en désactivant le css voire le js d\u0026rsquo;un site). Sur Firefox : Menu Affichage/style de la page/aucun style\nLa sémantique des balises Attention à la sémantique (le sens, la signification) des balises ! Cela est très important notamment pour les lecteurs d\u0026rsquo;écran de site web pour les personnes aveugles. Exemple :\n\u0026lt;button\u0026gt; = une action dans le site lui-même \u0026lt;a\u0026gt; = un lien, une redirection vers une autre page ou autre site Utilisation des balises \u0026lt;h*\u0026gt; Peu importe l\u0026rsquo;apparence des h*, les personnes qui voient les titres comprennent. En revanche les personnes qui naviguent avec le clavier au voiceOver ont besoin que le html soit explicite le plus possible pour que leur outil sache les lire correctement.\nConcrètement, ce n\u0026rsquo;est pas une mauvaise pratique d\u0026rsquo;avoir un h1 visuellement plus petit/moins contrasté/, etc. qu\u0026rsquo;un h2. On peut par exemple avoir une publicité, qui sera marquée par le titre h1 \u0026ldquo;Publicité\u0026rdquo;, mais qui visuellement sera tout petit. L\u0026rsquo;important est de conserver une structure html en cascade pour le voiceOver (et le référencement web).\nAu moins un h1 est nécessaire sur chaque page : ce sera le titre de la page. Exemple pour la page d\u0026rsquo;accueil du site service-public : \u0026ldquo;service-public particuliers : connaître vos droits effectuer vos demandes\u0026rdquo;. C\u0026rsquo;est important de mettre le nom du site global pour avoir du contexte. De plus, ce h1 doit contenir la même chose que le titre de la page.\nOn peut mettre une image dans un titre (exemple : image avec alt=« Pix » Connectez-vous)\nUtilisation des balises Dans l\u0026rsquo;idéal les balises div ne servent que pour des éléments décoratifs. Le reste doit avoir une balise spécifique.\nPlus d\u0026rsquo;informations Voir le site du w3c pour la liste des balises.\nQuand mettre un alt sur une image ? Il faut TOUJOURS mettre un alt sur une balise \u0026lt;img\u0026gt;.\nA noter cependant qu\u0026rsquo;il faut mettre l\u0026rsquo;alt vide si l\u0026rsquo;image est \u0026ldquo;décorative\u0026rdquo; (c\u0026rsquo;est-à-dire qu\u0026rsquo;elle peut être enlevée sans perdre d\u0026rsquo;informations, par exemple une image de fond). Pour savoir si une image est utile, se poser la question : \u0026ldquo;si on enlève l’image, est-ce qu’il nous manque un information ?\u0026rdquo;\nPour les autres images, jouant le rôle de boutons ou de lien etc., le contenu de l\u0026rsquo;alt est primordial. Par exemple, on préférera les formulations :\n\u0026ldquo;Retour vers l\u0026rsquo;accueil de Pix\u0026rdquo; plutôt que \u0026ldquo;Logo de Pix\u0026rdquo;, pour expliquer ce que fait le bouton avec l\u0026rsquo;image du logo de Pix dans le footer. \u0026ldquo;Nous suivre sur facebook\u0026rdquo; plutôt que \u0026ldquo;Lien vers notre page Facebook\u0026rdquo; (parce que l\u0026rsquo;information \u0026ldquo;lien\u0026rdquo; est déjà contenu dans la balise elle même). \u0026ldquo;Soutenu par le ministère de \u0026hellip;\u0026rdquo; plutôt que \u0026ldquo;Logo du ministère de \u0026hellip;\u0026rdquo; Unités CSS Pour les textes, les pixels sont à bannir ! Il faut privilégier les unités relatives. Utilisation des rem pour les fonts : size, lettering, letter-spaces. Utilisation des px pour le positionnement : padding, border, margin.\n.my-class { size: 1.3rem; padding: 10px 12px; } Navigation Normalement toute page est accessible via :\nBarre de recherche Barre de navigation Plan de site SAUF tunnel d’achat, etc…\nGraphiques Vérifier les contraste de couleurs Les couleurs qui portent à confusion ne doivent pas être côte à côte (on peut tester cela en convertissant l\u0026rsquo;écran en noir et blanc) Mettre des frontières/bordures épaisses Légende en dehors du graphique et complète (pas d\u0026rsquo;ellipse : \u0026hellip;) Pas d’affichage au survol Préférer une construction graphique avec une alternative textuelle : tableau portant les données dépliées dans un accordéon en dessous du graphique données en table, transformées visuellement en graphique : les lecteurs d\u0026rsquo;écran sauront lire correctement un tableau "},{"id":37,"href":"/pix/adr/","title":"Adr","parent":"Pix documentation technique","content":" Architecture Decision Record "},{"id":38,"href":"/pix/Anatomy/","title":"Anatomie de la plateforme","parent":"Pix documentation technique","content":" Organisation générale du code Les applications Pix (Pix API, Pix App, Pix Orga, Pix Certif et Pix Admin) sont organisées au travers un dépôt Git de type monorepo.\npix → Sources de la plateforme └ .circleci → Répertoire de configuration de CircleCI └ config.yml → Fichier principal de configuration de CircleCI └ admin → Sources de l\u0026#39;application Pix Admin └ api → Sources de l\u0026#39;application Pix API └ certif → Sources de l\u0026#39;application Pix Certif └ docs → Répertoire des documents techniques et méthodologiques └ adr → Registre des ADR (Architecture Decision Records) └ assets → Images utilisées dans la documentation └ high-level-tests → Répertoire de tests très haut niveau └ e2e → Tests fonctionnels avec Cypress.js └ load-testing → Tests de charge et de performance Artillery.io └ mon-pix → Sources de l\u0026#39;application Pix App └ node_modules → (généré) Dépendances pour les scripts et tâches NPM générales └ orga → Sources de l\u0026#39;application Pix Orga └ scripts → Divers scripts utilisés pour l\u0026#39;exploitation et le support └ .adr-dir → Fichier de configuration de l\u0026#39;outil npryce/adr-tools pour gérer les ADR └ .buildpacks → Fichier de définition des buildpacks Scalingo à utiliser └ .editorconfig → Fichier de configuration pour l\u0026#39;outil / standard EditorConfig └ .eslintrc.yaml → Fichier de configuration général pour l\u0026#39;outil de linting ESLint └ .gitignore → Listing des fichiers / répertoires à ignorer de Git └ .slugignore → Listing des fichiers / répertoires que Scalingo doit ignorer au moment du build └ CHANGELOG.md → Listing des modifications opérées sur la plateforme (mise à jour automatique) └ docker-compose.yml → Fichier utilisé pour les développements afin de démarrer un environnement iso-prod └ INSTALLATION.md → Instructions d\u0026#39;installation de la plateforme en local └ LICENSE.md → Texte de la licence logicielle utilisée sur Pix (AGPL-3.0) └ nginx.conf.erb → Fichier de configuration du reverse proxy / API gateway (Nginx) └ package.json → Fichier de définition généré de la plateforme └ package-lock.json → Listing des dépendances └ README.md → Fichier de présentation du projet └ scalingo.json → Fichier de configuration des Review Apps Scalingo Anatomie d\u0026rsquo;une application Ember cf. Documentation officielle d\u0026rsquo;Ember\nAnatomie de l\u0026rsquo;application Pix API Le code de l\u0026rsquo;application Pix API s\u0026rsquo;inspire des principes formulés par Robert C. Martin dans son modèle Clean Architecture.\napi → Sources de l\u0026#39;application Pix API └ bin → Répertoire de binaires └ www → Binaire d\u0026#39;exécution de l\u0026#39;API └ db → Fichiers de configuration et d\u0026#39;alimentation de la BDD └ migrations → Répertoire des fichiers de migration de la BDD └ seeds → Répertoire des fichiers d\u0026#39;alimentation de la BDD pour développement local └ knex-database-connection.js → Fichier de configuration de l\u0026#39;outil de requêtage SQL (Knex.js) └ knexfile.js → Fichier de configuration des environnements Knex └ lib → Sources de l\u0026#39;API └ application → Fichiers de définition des routes et contrôleurs HTTP └ domain → Objets du domaine (entités, aggrégats, value objects, services, use cases) └ models → Entités, aggrégats et value objects du domaine └ services → Services métier du domaine └ usecases → Cas d\u0026#39;usage métier └ validators → Validateurs de règles fonctionnelles └ constants.js → Listing des variables métier utilisées dans l\u0026#39;application └ errors.js → Listing des erreurs métier └ infrastructure → Ensemble des modules et briques techniques └ adapters → Convertisseurs d\u0026#39;objets issus de sources de données (PG, Airtable) en objets du domaine └ caches → Classes et modules utilisés pour le caching de données └ data → Modèles de données Bookshelf └ datasources → Modèles de données Airtable └ files → Templates de fichiers utilisés pour l\u0026#39;import / export de données └ mailers → Classes et modules utilisées pour l\u0026#39;envoi d\u0026#39;e-mails └ plugins → (déprécié) Plugins Hapi.js _home made_ └ repositories → Gestionnaires d\u0026#39;accès aux données (PG, Airtable) └ serializers → Convertisseurs de données Domain objects ←→ HTTP request objects └ utils → Ensemble de classes et modules utilitaires ou helpers └ validators → (déprécié) Validateurs techniques └ airtable.js → Wrapper de client Airtable └ bookshelf.js → Instance de gestionnaire Bookshelf └ logger.js → Instance de logger Bunyan └ node_modules → (généré) Dépendances pour les scripts et tâches NPM générales └ scripts → Divers scripts └ tests → Sources des tests suites et test cases └ acceptance → Tests haut niveau pour les scripts et certaines routes └ docs → Tests documentant l\u0026#39;emploi de dépendances utilisées sur Pix (ex : Bookshelf) └ integration → Tests utilisées pour couvrir les Routes, les modèles Bookshelf, les Repositories, et le traitement de fichiers └ tooling → Outillage (Factories, DataBuilders) pratique pour les tests └ unit → Tests unitaires (Controllers, Serializers, Models, Services et Usecases du domaine, Validators, etc.) └ .eslintrc.yaml → Fichier de configuration général pour l\u0026#39;outil de linting ESLint └ test-helper.js → Module de configuration des libs utilisées pour les tests (Mocha, Sinon, Chai, etc.) └ .buildpacks → Fichier de définiion des buildpacks Scalingo à utiliser └ .env → (généré/édité) Fichier avec les variables d\u0026#39;environnement pour le développement local └ .eslintrc.yaml → Fichier de configuration général pour l\u0026#39;outil de linting ESLint └ .istanbul.yml → Fichier de configuration pour la couverture de code └ .slugignore → Listing des fichiers / répertoires que Scalingo doit ignorer au moment du build └ package.json → Fichier de définition généré de la plateforme └ package-lock.json → Listing des dépendances └ Procfile → Fichier de démarrage du conteneur Scalingo └ sample.env → Template du fichier .env └ server.js → Instance du Web server Hapi.js "},{"id":39,"href":"/pix/API/","title":"API","parent":"Pix documentation technique","content":" Conventions de nommage Les classes prennent une majuscule au début. Les modules et variables prennent une minuscule au début. Sauf exception, privilégier l\u0026rsquo;ordre alphabétique pour trier une suite de déclarations, require, \u0026hellip;\n// BAD const sessionRepository = require(...); const assessmentRepository = require(...); const certificationRepository = require(...); // GOOD const assessmentRepository = require(...); const certificationRepository = require(...); const sessionRepository = require(...); Exemples :\nconst User = require(...); const userRepository = ... const userName = ... Une entité du domaine ne contient pas de préfixe.\nconst User = require(\u0026#39;../../User\u0026#39;); const myUser = new User({}); Déclaration de routes Ajout de tags et de notes au moment de la déclaration des routes de l\u0026rsquo;API.\nserver.route([ { method: \u0026#39;GET\u0026#39;, path: \u0026#39;/api/sessions\u0026#39;, config: { handler: sessionController.find, tags: [\u0026#39;api\u0026#39;, \u0026#39;sessions\u0026#39;], notes: [ \u0026#39;- **Cette route est restreinte aux utilisateurs authentifiés avec le rôle Pix Master**\\n\u0026#39; + \u0026#39;- Elle permet de consulter la liste de toutes les sessions (retourne un tableau avec n éléments)\u0026#39;, ] } } ] ); Configuration Options d\u0026rsquo;environnement Toute option de configuration de l\u0026rsquo;API susceptible de dépendre d\u0026rsquo;un environnement particulier (production, intégration, développement ou test), qu\u0026rsquo;elle soit fonctionnelle ou technique, DOIT être définie dans le fichier /api/lib/config.js.\nconfig.config.jsexports = (function() { const config = { // some options… someCategory: { optionA: \u0026#39;valueA\u0026#39;, optionB: \u0026#39;valueB\u0026#39;, }, // yet other options… }; return config; })(); L\u0026rsquo;accès à une variable d\u0026rsquo;environnement NE DOIT PAS être effectué en dehors des fichiers `/api/lib/settings.config.\n// BAD /* lib/plugins.js */ if (process.env.LOG_ENABLED === \u0026#39;true\u0026#39;) { consoleReporters.push(\u0026#39;stdout\u0026#39;); } // GOOD /* lib/config.js */ module.exports = (function() { const config = { logging: { enabled: (process.env.LOG_ENABLED === \u0026#39;true\u0026#39;), }, }; return config; })(); /* lib/plugins.js */ const settings = require(\u0026#39;./settings\u0026#39;); if (settings.logging.enabled) { consoleReporters.push(\u0026#39;stdout\u0026#39;); } Toute variable d\u0026rsquo;environnement DOIT être définie dans la page du wiki concernée.\nSurcharge d\u0026rsquo;une option par environnement La surcharge d\u0026rsquo;une option pour un environnement dédié DOIT se faire par modification de la valeur plutôt que par instanciation d\u0026rsquo;un nouvel objet associé à la catégorie, afin de permettre le mécanisme de \u0026ldquo;valeur par défaut\u0026rdquo; et d\u0026rsquo;éviter la duplication de code inutile.\nSoit la configuration par défaut suivante :\nconst config = { someCategory: { optionA: \u0026#39;valueA\u0026#39;, optionB: \u0026#39;valueB\u0026#39;, optionC: \u0026#39;valueC\u0026#39;, }, }; // BAD if (process.env.NODE_ENV === \u0026#39;test\u0026#39;) { config.someCategory = { optionA: \u0026#39;test_valueA\u0026#39;, optionB: \u0026#39;test_valueB\u0026#39;, optionC: \u0026#39;test_valueC\u0026#39;, }; } // GOOD if (process.env.NODE_ENV === \u0026#39;test\u0026#39;) { config.someCategory.optionA = \u0026#39;test_valueA\u0026#39;; config.someCategory.optionB = \u0026#39;test_valueB\u0026#39;; config.someCategory.optionC = \u0026#39;test_valueC\u0026#39;; } Activation / désactivation des fonctionnalités Dans le cas de fonctionnalités activables/désactivables, l\u0026rsquo;activation DOIT être gérée via une option booléenne enabled.\n// BAD mailing: { enabled: !!process.env.MAILING_ENABLED, } // GOOD mailing: { enabled: (process.env.MAILING_ENABLED === \u0026#39;true\u0026#39;), } Catégorisation des options Toute option DEVRAIT être classée dans une catégorie spécifique afin d\u0026rsquo;aider à comprendre la finalité, l\u0026rsquo;usage ou le contexte d\u0026rsquo;exécution de celle-ci.\n// BAD const config = { passwordValidationPattern: \u0026#39;^(?=.*\\\\p{L})(?=.*\\\\d).{8,}$\u0026#39;, }; // GOOD const config = { account: { passwordValidationPattern: \u0026#39;^(?=.*\\\\p{L})(?=.*\\\\d).{8,}$\u0026#39;, }, }; Tests ♻️ Tests unitaires Un test unitaire doit passer sans base de données.\nFeature Toggles 🗺️ Problème On veut pouvoir mettre en prod une fonctionnalité (exemple \u0026ldquo;Certification v2\u0026rdquo;), tout en ayant la capacité de la désactiver sans générer une nouvelle version de l\u0026rsquo;application pendant les premières semaines.\nSur des fonctionnalités longues à développer, on a aussi parfois le besoin de livrer une partie du code en production sans que la fonctionnalité associée soit visible par l\u0026rsquo;utilisateur.\n🥚 Solution Ajouter des variables d\u0026rsquo;environnement dont le nom est clairement identifié comme feature toggle en utilisant le préfixe FT_ :\nFT_ACTIVATE_CERTIFICATION_V2 = true Dans leur formulation, les variables d\u0026rsquo;env sont en tournure affirmative :\nFT_USE_ONLY_V1_CERTIFICATION plutôt que FT_DONT_USE_V2_CERTIFICATION. Leur valeur par défaut est false de préférence (=\u0026gt; oublier de l\u0026rsquo;ajouter conserve le comportement actuel de l\u0026rsquo;application).\n⚠️ : il est important de supprimer ces bascules au plus tôt, dès que la feature est bien installée en production (voir référence de Martin Fowler ci-dessous). Les features toggles ne sont pas des configurations qu\u0026rsquo;on souhaite conserver longtemps, ce sont des bascules temporaires.\nAvoir un préfixe bien identifié permet de faire la différence entre les variables d\u0026rsquo;environnement de configuration durables et les variables d\u0026rsquo;environnement de bascules temporaires.\n⚠️ : cette solution de feature toggle doit rester un pis aller quand on ne sait pas découper finement une fonctionnalité. Ça ne doit pas devenir un réflexe. On ne le fait que quand on n\u0026rsquo;a pas trouvé de meilleure solution.\n📖 Informations supplémentaires Pour tester en évitant une combinatoire ingérable pendant les tests (telle fonctionnalité activée avec telle autre désactivée, \u0026hellip;), Martin Fowler propose de ne tester que deux cas :\nTester avec toutes les bascules qui seront effectivement activées lors de la prochaine livraison Tester avec toutes les bascules activées Par exemple, si :\nJ\u0026rsquo;ajoute la bascule FT_ACTIVATE_CERTIFICATION_V2, Et que cette bascule sera désactivée à la prochaine mise en prod Alors :\nJe teste avec FT_ACTIVATE_CERTIFICATION_V2=false (et l\u0026rsquo;état des autres FT tel qu\u0026rsquo;en production) Je teste avec FT_ACTIVATE_CERTIFICATION_V2=true (et toutes les autres FT activées également) Références https://martinfowler.com/bliki/FeatureToggle.html https://martinfowler.com/articles/feature-toggles.html Voir un exemple d\u0026rsquo;ajout en PR #534, et de suppression en PR #563. "},{"id":40,"href":"/pix/database/","title":"Base de données","parent":"Pix documentation technique","content":"Ces conventions sont vérifiées dans la tâche de lint de l\u0026rsquo;API.\nNommage Tables Le nom d\u0026rsquo;une table :\nest au pluriel : users et pas user Exceptions Les exceptions possibles sont :\nles tables utilisées par les librairies, par exemple la table knex_migrations_lock utilisée par la librairie knex; les tables ne contenant qu\u0026rsquo;un seul enregistrement (aucun exemple connu). Dans ce cas, elles peuvent être ajoutées à la propriété ignores du fichier de configuration.\nignores: [ {identifierPattern: \u0026#39;public\\\\.knex*.*\u0026#39;, rulePattern: \u0026#39;.*\u0026#39;}, {identifierPattern: \u0026#39;public\\\\.badge-criteria\u0026#39;, rulePattern: \u0026#39;name-inflection\u0026#39;}, ] "},{"id":41,"href":"/pix/Calcul-Airtable/","title":"Calcul des Pix dans Airtable","parent":"Pix documentation technique","content":" Règle de calcul des Pix Rappel de la règle de calcul :\nOn ne considère dans la suite que les Acquis : Ayant le champ Status à actif ; Associé à au moins une épreuve ayant le champ Statut à validé, validé sans test ou pré-validé. Associé à une Compétence dont le champ Origine est Pix Pour chaque Acquis : On compte le nombre d\u0026rsquo;acquis : de la même compétence ; et de même niveau. On divise 8 par ce nombre pour obtenir la valeur en Pix ; si le résultat est supérieur à 4 la valeur est limitée à 4. Ajouter les champs de calcul des Pix Rappel : la hiérarchie d\u0026rsquo;objets concernée est la suivante :\nChaque Compétence : contient des Tubes… qui contiennent des Acquis… qui contiennent des Epreuves. L\u0026rsquo;idée est de construire en remontant la liste des niveaux des acquis jusqu\u0026rsquo;à leur compétence, puis de la redescendre jusqu\u0026rsquo;à chaque acquis qui peut ensuite déterminer combien d\u0026rsquo;acquis dans sa compétence ont le même niveau que lui.\nSont ajoutés les champs suivants, dans l\u0026rsquo;ordre où ils sont évalués :\nEpreuves.IsValidated qui vaut 1 si l\u0026rsquo;épreuve est considérée \u0026ldquo;validée\u0026rdquo; (règle 1.b), et 0 sinon ; Field type : Formula Formule : IF(OR({Statut}=\u0026ldquo;validé\u0026rdquo;, {Statut}=\u0026ldquo;validé sans test\u0026rdquo;, {Statut}=\u0026ldquo;pré-validé\u0026rdquo;), 1,0) Exemple de résultat : 1 Acquis.LevelIfActive qui vaut le niveau (Level) de l\u0026rsquo;acquis si le Status est actif (règle 1.a) et qu\u0026rsquo;il existe une épreuve validée (règle 1.b), sinon une chaîne vide ; Pour savoir s\u0026rsquo;il existe une épreuve validée, ce champ est un rollup du champ IsValidated des épreuves associées à l\u0026rsquo;acquis ; en faisant la somme des IsValidated on sait s\u0026rsquo;il existe ou non une épreuve validée; Field type : Rollup Formule : IF(AND(SUM(values) \u0026gt; 0, Status=\u0026ldquo;actif\u0026rdquo;), Level, \u0026ldquo;\u0026rdquo;) Exemple de résultat : 3 Tubes.AcquisLevels qui calcule la concaténation des LevelIfActive des Acquis contenus dans le tube ; Field type : Rollup Formule : CONCATENATE(values) Exemple de résultat : 1245 Acquis.Origin qui recopie le champ Origine de la compétence sur chacun de ses Tubes ; Field type : Lookup Exemple de résultat : \u0026ldquo;Pix\u0026rdquo; Competences.AcquisLevels qui fait à son tour la concaténation des AcquisLevels remontés sur les Tubes ; Field type : Rollup Formule : CONCATENATE(values) Exemple de résultat : 1544352134513675445363453124351241234 Tubes.CompetenceAcquisLevels qui recopie le champ AcquisLevels de la compétence sur chacun de ses Tubes ; Field type : Lookup Exemple de résultat : 1544352134513675445363453124351241234 Acquis.PixValue qui récupère le CompetenceAcquisLevels de son Tube et dispose donc de la liste complète des niveaux d\u0026rsquo;acquis présents dans sa compétence, et l\u0026rsquo;utilise pour calculer sa valeur en Pix : Si l\u0026rsquo;acquis n\u0026rsquo;est pas actif au sens de la règle 1, sa valeur est simplement mise à zéro ; Si l\u0026rsquo;acquis n\u0026rsquo;est pas d\u0026rsquo;origine Pix, sa valeur est simplement mise à zéro ; Sinon, on doit déterminer dans la chaîne des niveaux le nombre d\u0026rsquo;occurrences du niveau de l\u0026rsquo;acquis considéré. Comme Airtable ne fournit pas de fonction donnant directement ce nombre, on calcule la différence entre la longueur de la chaîne originale (ex. 12434132), et cette même chaîne dans laquelle on aurait remplacé notre niveau (ex. 2) par une chaîne vide (ex. 143413), ce qui donne bien le nombre d\u0026rsquo;occurrences du niveau dans la compétence ; Il ne reste qu\u0026rsquo;à diviser 8 par ce nombre et limiter à 4 le résultat ; Field type : Rollup Formule : IF(LevelIfActive \u0026gt; 0, MIN(4, 8/(LEN(CONCATENATE(values)) - LEN(SUBSTITUTE( CONCATENATE(values),LevelIfActive,\u0026quot;\u0026quot;)))), 0) Noter que même si à la base on a une simple copie d\u0026rsquo;une valeur de l\u0026rsquo;enregistrement Tube lié, ce qui correspond plutôt à un lookup on utilise ici un champ de type rollup pour pouvoir appliquer une formule. Du coup on est obligé de faire un CONCATENATE(values) pour obtenir la valeur de CompetenceAcquisLevels ; Il est utile de changer le formatage par défaut du champ pour afficher quelques décimales ; Exemple de résultat : 1.333 "},{"id":42,"href":"/pix/CSS/","title":"Classes CSS","parent":"Pix documentation technique","content":" Conventions de nommage Privilégier le plus possible la Convention Block__Element\u0026ndash;Modifier BEM.\nQuand on reprend l\u0026rsquo;élément pour devenir un block, il n\u0026rsquo;est pas obligatoire de reprendre l\u0026rsquo;élément parent.\nPar exemple, avec le parent profilv2-header__hexagon-score, l\u0026rsquo;enfant doit devenir hexagon-score__content. On n\u0026rsquo;est pas obligé de l\u0026rsquo;appeler profilv2-header-hexagon-score__content.\nSelon BEM, les classes ne doivent pas refléter la structure arborescente du DOM, et être le plus flat possible. Puisque par définition d\u0026rsquo;un block, tout ce qui est de la forme block__element-n est un tout indivisible.\nCréation de classes CSS La création de classes CSS peut se faire dans le .hbs ou dans le .js, en fonction du besoin.\nDans le .js Lorsque la classe css n\u0026rsquo;a pas de besoin de propriétés particulières, il suffit de la déclarer dans le .js.\nexport default Component.extend({ classNames: [\u0026#39;hexagon-score\u0026#39;], // qui va rajouter cette class à la div créée par Ember pour injecter le component }); \u0026lt;div class=\u0026#34;hexagon-score__content\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;hexagon-score-content__title\u0026#34;\u0026gt;PIX\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;hexagon-score-content__pix-score\u0026#34;\u0026gt;{{score}}\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;hexagon-score-content__pix-total\u0026#34;\u0026gt;1024\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; Au niveau de la structure html, la div apparaitra sous la forme suivante :\n\u0026lt;div class=\u0026#34;ember-view\u0026#34; id=\u0026#34;ember123\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;hexagon-score__content\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;hexagon-score-content__title\u0026#34;\u0026gt;PIX\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;hexagon-score-content__pix-score\u0026#34;\u0026gt;{{score}}\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;hexagon-score-content__pix-total\u0026#34;\u0026gt;1024\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; Dans le .hbs Lorsque la classe css a besoin de propriétés particulières, il suffit de la déclarer dans le .hbs. Au niveau de la structure html, le structure sera identique au .hbs.\nexport default Component.extend({ // component stuff }); \u0026lt;div class=\u0026#34;hexagon-score\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;hexagon-score__content\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;hexagon-score-content__title\u0026#34;\u0026gt;PIX\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;hexagon-score-content__pix-score\u0026#34;\u0026gt;{{score}}\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;hexagon-score-content__pix-total\u0026#34;\u0026gt;1024\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; Responsabilités Dans une recherche de réutilisabilité des classes css, il faut dans l\u0026rsquo;idéal que :\nLe bloc comporte le style. L’élément comporte le positionnement. Le modifier modifie de façon mineure certaines descriptions de style du bloc. Une modification majeure marque le besoin de créer une nouvelle classe / un nouvel “objet” css Ces \u0026ldquo;règles\u0026rdquo; ne vont pas forcément s\u0026rsquo;appliquer sur des composants uniques.\nImbrication en poupées russes Privilégier le plus possible la création de classes filles visuellement plus petites que leur classe parente, à l\u0026rsquo;image des poupées russes.\nRegroupements des génériques Rassembler les couleurs dans un seul et même fichier .scss (palette.scss ou colors.scss)\nSéparation des responsabilités Séparer le style du positionnement. On peut par exemple utiliser @mixin. L\u0026rsquo;idée est de dissocier facilement et a minima le style du positionnement pour pouvoir éventuellement réutiliser le style ailleurs. Même si c\u0026rsquo;est préférable, il ne s\u0026rsquo;agit pas forcément de séparer les classes au moment du processing.\n// BAD .hexagon-score-content__pix-score { position: absolute; width: 100%; top: 40px; color: $black; font-family: $font-open-sans; font-size: 4.6rem; } // GOOD @mixin hexagon-score-pix-score { color: $black; font-family: $font-open-sans; font-size: 4.6rem; } .hexagon-score-content__pix-score { @include hexagon-score-pix-score; position: absolute; width: 100%; top: 40px; } "},{"id":43,"href":"/pix/Contribuer/","title":"Contribuer à Pix","parent":"Pix documentation technique","content":" title: Contribuer à Pix Pour toute contribution, il est essentiel de respecter a minima les points suivants. Pour aller plus loin, vous pouvez parcourir les différents fichiers présentés dans le README.md\nRègles de bonnes conduites pour déclarer les problèmes Utilisez toujours https://github.com/1024pix/pix/issues pour déclarer des problèmes.\nRègles de bonnes conduites pour ouvrir une pull request Format Le format à respecter est le suivant : [\u0026lt;TAG\u0026gt;] \u0026lt;DESCRIPTION\u0026gt; (\u0026lt;PROJET_REF-\u0026lt;US_ID\u0026gt;)., ex : \u0026ldquo;[FEATURE] Création de compte (US-987).\u0026rdquo;\nTAG Nom Usage FEATURE PR relative à une story BUGFIX PR relative à une correction d\u0026rsquo;un bug TECH PR relative à du code technique / d\u0026rsquo;infra Ce tag nous permet de générer automatiquement un fichier CHANGELOG.md regroupant les modifications d\u0026rsquo;une version à l\u0026rsquo;autre. Il est possible d\u0026rsquo;utiliser d\u0026rsquo;autres tags mais le CHANGELOG les regroupera comme des modifications \u0026ldquo;Autres\u0026rdquo;.\nLe titre de la PR originel (et donc son tag) reste dans tous les cas affiché dans chaque ligne du CHANGELOG.\nDESCRIPTION La description de l\u0026rsquo;US doit être en français, car il s\u0026rsquo;agit d\u0026rsquo;un produit francophone. Par ailleurs, on souhaite que le CHANGELOG puisse être compris par des intervenants non techniques, par exemple des utilisateurs.\nOn suit la convention que la description doit marcher comme une fin de phrase à Une fois mergée, cette _pull request_ permettra de ….\n// BAD // Serialise tout les badgeParnerCompetences // Proposition d\u0026rsquo;ADR pour séparer Domain Transactions et Domain Events\n// GOOD // Sérialiser tout les badgeParnerCompetences // Proposer un ADR pour séparer Domain Transactions et Domain Events\nPROJET_REF PROJET_REF correspond à l\u0026rsquo;abréviation du projet logiciel dans notre gestionnaire de tickets.\nUS_ID US_ID correspond à l\u0026rsquo;identifiant unique de la story dans le Product Backlog, généré et géré par notre gestionnaire de tickets.\nInstallation de l\u0026rsquo;environnement de développement local Voir INSTALLATION\nConventions de nommage Applications Le nom des applications respecte le modèle suivant \u0026lt;Pix [activity_shortname]\u0026gt; Ex : \u0026ldquo;Pix App\u0026rdquo;, \u0026ldquo;Pix Admin\u0026rdquo;, \u0026ldquo;Pix Orga\u0026rdquo;, \u0026ldquo;Pix API\u0026rdquo;, \u0026ldquo;Pix Certif\u0026rdquo;\nCommits Les messages de commit doivent être rédigés en anglais (décision d\u0026rsquo;équipe du 27/04/2017).\n50 caractères au maximum pour respecter les conventions de l’écosystème notamment GitHub.\nMajuscule et verbe d’action pour être en harmonie avec les conventions de Git.\nSi le message n\u0026rsquo;est pas 100 % autoportant, on peut ajouter une description (après une ligne vide) qui explique la motivation du commit.\nOn suit la convention que le sujet doit marcher comme une fin de phrase à If applied, this commit will… .\nA properly formed Git commit subject line should always be able to complete the following sentence:\nIf applied, this commit will _Your subject line here_ For example:\nIf applied, this commit will _Refactor subsystem X for readability_ If applied, this commit will _Update getting started documentation_ If applied, this commit will _Remove deprecated methods_ If applied, this commit will _Release version 1.0.0_ If applied, this commit will _Merge pull request #123 from user/branch_ Pour aller plus loin :\nCommit messages guide Git SCM commit guidelines https://chris.beams.io/posts/git-commit/ Branches Format (*) Description Exemples [projet_ref]-[us_id]-[description] Branche qui porte sur le développement d\u0026rsquo;une story pf-123-create-account [projet_ref]-[us_id]-bugfix-[description] Branche qui porte sur la correction d\u0026rsquo;un bug pf-124-bugfix-timeout-ko [projet_ref]-[us_id]-cleanup-[description] Branche qui sert à du refactoring pf-125-cleanup-add-tests [projet_ref]-[us_id]-infra-[description] Branche contenant du code technico-technique pf-126-infra-backup-db [projet_ref]-[us_id]-doc-[description] Branche liée à de la documentation (code ou README) pf-127-doc-readme-live [projet_ref]-[us_id]-hotfix-[description] Branche de correction de bugs de production pf-128-hotfix-regression tech-[description] Branche avec changements techniques tech-upgrade-cicd-script (*) : la description est en anglais\nAutres Branche dev ⚠️ On ne merge jamais dev dans une autre branche ⚠️\nNode.js On ne commit le package-lock.json qu\u0026rsquo;en cas de modification du package.json\n"},{"id":44,"href":"/pix/Ember/","title":"Ember","parent":"Pix documentation technique","content":" Général Utilisation de transitionTo Éviter les transistionTo dans le hook model(). Privilégier leur utilisation dans l’afterModel(), une fois que le modèle est chargé.\n// BAD export default Route.extend({ model() { const store = this.get(\u0026#39;store\u0026#39;); return store.findRecord(\u0026#39;user\u0026#39;, this.get(\u0026#39;session.data.authenticated.userId\u0026#39;)) .then((user) =\u0026gt; { if (user.get(\u0026#39;organizations.length\u0026#39;) \u0026gt; 0) { return this.transitionTo(\u0026#39;board\u0026#39;); } return user; }); }, }); // GOOD export default Route.extend({ model() { return this.store.findRecord(\u0026#39;user\u0026#39;, this.get(\u0026#39;session.data.authenticated.userId\u0026#39;)); }, afterModel(model) { if (model.get(\u0026#39;organizations.length\u0026#39;) \u0026gt; 0) { return this.transitionTo(\u0026#39;board\u0026#39;); } } }); Tests Tester le texte traduit par EmberIntl Afin d\u0026rsquo;être complètement agnostique de la locale de l\u0026rsquo;environnement de test, on privilégiera le fait de tester les textes traduits en passant par le helper t fourni par ember-intl/test-support. Ainsi, on s\u0026rsquo;affranchira de la contrainte de langue et on se concentrera plutôt sur la clé de traduction attendue sur un test donné (procédé documenté dans la doc EmberIntl).\nPour tester les textes traduits dans les templates :\nimport { module, test } from \u0026#39;qunit\u0026#39;; import { render } from \u0026#39;@ember/test-helpers\u0026#39;; import hbs from \u0026#39;htmlbars-inline-precompile\u0026#39;; import { setupRenderingTest } from \u0026#39;ember-qunit\u0026#39;; import { setupIntl, t } from \u0026#39;ember-intl/test-support\u0026#39;; module(\u0026#39;Integration | Component | hello\u0026#39;, function(hooks) { setupRenderingTest(hooks); setupIntl(hooks); test(\u0026#39;it should display a welcome message\u0026#39;, async function (assert) { // when await render(hbs`\u0026lt;Hello/\u0026gt;`); // then assert.dom().hasText(t(\u0026#39;pages.hello.welcome-message\u0026#39;)); }); }); De même, pour tout autre texte traduit par un autre biais :\nimport { module, test } from \u0026#39;qunit\u0026#39;; import { setupTest } from \u0026#39;ember-qunit\u0026#39;; import { setupIntl, t } from \u0026#39;ember-intl/test-support\u0026#39;; module(\u0026#39;Unit | Service | Error messages\u0026#39;, function(hooks) { setupRenderingTest(hooks); setupIntl(hooks); test(\u0026#39;should return the message when error code is found\u0026#39;, function(assert) { // given const errorMessages = this.owner.lookup(\u0026#39;service:errorMessages\u0026#39;); // when const message = errorMessages.getErrorMessage(\u0026#39;CAMPAIGN_NAME_IS_REQUIRED\u0026#39;); // then assert.equal(message, t(\u0026#39;api-errors-messages.campaign-creation.name-required\u0026#39;)); }); }); Enfin, si vraiment on souhaite tester une traduction spécifique, il faut alors spécifier la locale lors du setup de test :\nimport { module, test } from \u0026#39;qunit\u0026#39;; import { setupTest } from \u0026#39;ember-qunit\u0026#39;; import { setupIntl, t } from \u0026#39;ember-intl/test-support\u0026#39;; module(\u0026#39;Unit | Service | Error messages\u0026#39;, function(hooks) { setupRenderingTest(hooks); setupIntl(hooks, \u0026#39;fr-fr\u0026#39;); test(\u0026#39;should return the message when error code is found\u0026#39;, function(assert) { // given const errorMessages = this.owner.lookup(\u0026#39;service:errorMessages\u0026#39;); // when const message = errorMessages.getErrorMessage(\u0026#39;CAMPAIGN_NAME_IS_REQUIRED\u0026#39;); // then assert.equal(message, \u0026#39;Le nom de la campagne est obligatoire\u0026#39;); }); }); Note: La pratique n\u0026rsquo;est pas recommandée sauf exception\n"},{"id":45,"href":"/pix/","title":"Pix documentation technique","parent":"","content":""},{"id":46,"href":"/pix/pull_request_template/","title":"Pull request template","parent":"Pix documentation technique","content":" :unicorn: Problème Décrivez ici le besoin ou l\u0026rsquo;intention couvert par cette Pull Request.\n:robot: Solution Ajoutez à cet endroit, si nécessaire, des détails concernant la solution technique retenue et mise en oeuvre, des difficultés ou problèmes rencontrés.\n:rainbow: Remarques Des infos supplémentaires, trucs et astuces ?\n:100: Pour tester Les instructions pour reproduire le problème, les profils de test, le parcours spécifique à utiliser, etc.\n"},{"id":47,"href":"/pix/Responsive-Design/","title":"Responsive Design","parent":"Pix documentation technique","content":" Dimensionnement La largeur doit prendre soit 100% soit une largeur maximale fixe définie en px.\n// BAD .my-class { width: 70%; } // GOOD .my-class { width: 100%; } // ALSO GOOD .my-class { max-width: 1200px; } Positionnement Éviter le plus possible les valeurs négatives de margin, padding, etc. et privilégier les positions absolutes\n// BAD .my-class { display: flex; margin-top: -9875654px; } // GOOD .my-class { position: absolute; top: 20px; left: 5px; right: 24132px; bottom: 12345px; } Pros CSS plus robuste c\u0026rsquo;est à dire à quel point mon CSS fait le design attendu lorsque le CSS autour de lui bouge.\nCons Lisibilité plus faible puisqu\u0026rsquo;en position absolute, le parent doit être en position relative, etc. On modifie plus de classes que besoin.\n"},{"id":48,"href":"/pix/tags/","title":"Tags","parent":"Pix documentation technique","content":""},{"id":49,"href":"/pix/test/","title":"Tests","parent":"Pix documentation technique","content":" Introduction Ce document rassemble les pratiques constatées et faisant consensus, afin de faciliter le développement, et notamment les revues de code. Son but n\u0026rsquo;est pas d\u0026rsquo;imposer une pratique, mais de capitaliser les bonnes pratiques.\nFavoriser dans ce document :\nla motivation des choix l\u0026rsquo;utilisation d\u0026rsquo;exemples Généralités Vocabulaire Ici:\nobjet ne fait pas référence à la programmation orientée objet composant ne fait pas référence au composant Ember. Ce sont des synonymes pour ce qui est en train d\u0026rsquo;être testé (anglais : SUT)\nLes objets utilisés afin de tester de manière isolée sont appelés doublures (anglais: test double). Ils regroupent les mocks, stubs, spy, fake, dummy.\nTypes de test Type de test Abbr Anglais Ce qui est vérifié unitaire TU unit le comportement d\u0026rsquo;une unité de code (fonction ou d\u0026rsquo;une méthode) de manière isolée (ex : pas d\u0026rsquo;appel BDD) intégration TI integration le résultat de l\u0026rsquo;interaction de N unités de code (composants) dans une configuration proche de celle de production (ex : BDD, Redis, Nock ) acceptation TA acceptance le fonctionnement d\u0026rsquo;une application (ex: Pix App, Pix API) en limitant les doublures à ce qu\u0026rsquo;on ne maîtrise pas (ex: Airtable) bout-en-bout E2E end to end le fonctionnement de la plateforme (traverser toutes les couches front et back) Les tests d\u0026rsquo;intégration, d\u0026rsquo;acceptation et bout-en-bout vérifient l\u0026rsquo;interaction de composants à des niveaux de plus en plus élevés, le dernier étant le Système d\u0026rsquo;Information complet.\nLes avantages/inconvénients de chaque type de test et la répartition de ceux-ci sont décrits par la pyramide des tests\nFrontières de test Ne pas tester les dépendances sortant du dépôt Git concerné (ex: depuis le dépôt pix, ne pas tester pix-ui ou mocha). Ces librairies ou framework sont choisies de telle manière à ce que l\u0026rsquo;on puisse avoir confiance en elles, elles font l\u0026rsquo;objets de tests dans leur propre dépôt. En revanche, tester l\u0026rsquo;intégration de ces dépendances dans le code, notamment des wrappers.\nBack - API Type de test par objet Conteneur Objet Type de test application route intégration controller unitaire ________________ ________________________ _______________ domain events unitaire models unitaire read-model unitaire service unitaire use-case unitaire ? use-case intégration ? validator intégration ________________ ________________________ _______________ infrastructure repository intégration serializer unitaire wrapper intégration autres unitaire wrapper : tout composant qui encapsule une dépendance ou une API\nSendinblueProvider.js airtable.js RedisClient.js Exemple :\nit(\u0026#39;should add a row in the table \u0026#34;organizations\u0026#34;\u0026#39;, async () =\u0026gt; { // given const nbOrganizationsBeforeCreation = await BookshelfOrganization.count(); // when await organizationRepository.create(domainBuilder.buildOrganization()); // then const nbOrganizationsAfterCreation = await BookshelfOrganization.count(); expect(nbOrganizationsAfterCreation).to.equal(nbOrganizationsBeforeCreation + 1); }); Unitaire Exemple:\nuse-case ici composant avec un service, non stubbé ici Intégration L\u0026rsquo;utilisation de Bookshelf, Knex, Nock pour faire des assertions est autorisé. Exemple:\nentre HAPI et configuration de la route ici Acceptation Exemple:\nsur l\u0026rsquo;application : ici Front Généralités Conforme aux préconisations Ember\nType de test par composant Objet Type de test route unitaire route acceptation controller unitaire component intégration (rendering) model unitaire serializer unitaire adapter unitaire helper unitaire authenticator unitaire Tracked properties Elles sont testées unitairement, peu importe leur nature (component, controller, route)\nBout-en-bout Raison: éviter les tests manuels, longs et répétitifs, de non-régression\n"},{"id":50,"href":"/pix/Usecase/","title":"Use-case","parent":"Pix documentation technique","content":" Définition Un use-case:\nest une fonction utilise le pattern RORO require seulement des éléments venant du domaine récupèrent leurs dépendances vers l\u0026rsquo;extérieur en tant que paramètres donnée à la fonction // BAD const myRepository = require(\u0026#39;../../../infrastructure/repositories/myRepository\u0026#39;); // GOOD const myService = require(../../../domain/services/myService); module.exports = function myUseCase({ param1, param2, param3, repo1, repo2 }) { ... }; Controllers Un controller ne peux pas appeler 2 use-case séquentiellement.\n"}]